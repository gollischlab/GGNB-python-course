{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Spike Triggered Average – STA**\n",
    "\n",
    "We have already looked into how to handle and analyze spike trains recorded under visual stimulation. We will now turn to a very common tool in systems neuroscience, the spike triggered average. \n",
    "\n",
    "**(here goes the theory, if not in a separate presentation)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You will learn to:**\n",
    "-  Match the signal from the stimulus generator to the actual presentation of the stimulus.\n",
    "-  Collect the stimulus portions preceding each spike, given a certain time window.\n",
    "-  Find the average stimulus that evokes spiking.\n",
    "-  **(simulation, fitting, shuffle analysis?)**\n",
    "\n",
    "First, let's import relevant packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.rc={'figure.figsize': (12, 6), 'font.size': 14 }\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Full-field flicker stimulus**\n",
    "\n",
    "The data you are going to work with comes from extracellular recording of a retinal ganglion cell while stimulated with a full-field flicker, a stimulus consisting of a screen-wide presentation of contrast levels that changed with a given frequency. The contrast value of each presentation is calculated from a number that's been taken \"randomly\" from a (...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](fff.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Loading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path(\"\")\n",
    "\n",
    "data = load(filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the file just loaded has a number of variables stored, whose names can be retrieved in a list so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to see the value of each variable, we retrieve it so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"name_of_the_variable\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to be able to manipulate the variables, we can assign their values to new variables. Keeping the original name is the most logical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_variable = data[\"name_of_the_variable\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with all things, there's a more straightforward way to update the file variables to our workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locals().update(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us go over what each of these variables represent, beginning with \"volts\". As its name suggests, it is the actual voltage recording, i.e., a list of numbers corresponding to the voltage values recorded throughout the experiment. Let's do a sanity check and see if we have spikes to begin with. To visualize the voltage trace, plot this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(volts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't be working further with the volts variable and will now focus on the other three: \"spikes\", \"ttls\" and \"stim_rand_nums\". \"spikes\" is a list of numbers representing timestamps –in seconds– of each occurrence of a spike. \"ttls\" is a list of timestamps of pulses that are generated to signal the presentation of the stimulus, so \"ttls\" is a list of the time points when the stimulus changed. \"stim_rand_nums\" is the sequence of \"random\" numbers that determined the contrast of each stimulus presentation, and for simplicity we will take them as a \"measure\" of contrast. Let's carry out another sanity check and confirm if, as should be expected already, the size of \"ttls\" and \"stim_rand_nums\" is the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START CODE HERE###\n",
    "\n",
    "###END CODE HERE###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we are going to collect the stimulus section preceding each spike. But, whatever the size of the sections, how much time do they represent? We must first consider that a given sequence of contrast values (random numbers) will correspond to as many stimulus presentations, so the time it took to show those contrast levels equals the number of stimulus presentation multiplied by the time elapsed from one stimulus presentation to the next. The former value we have in the desired size of our stimulus sections, whereas the latter we find by calculating the difference between any two consecutive values or, even better, the average of the differences between all pairs of consecutive values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START CODE HERE###\n",
    "tlls[10] - ttls [9]\n",
    "\n",
    "diff = np.diff(ttls)\n",
    "avg_diff = diff.mean()\n",
    "\n",
    "###END CODE HERE###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since different cells integrate information over different stretches of time, we have to try with different time windows, where 0.5-2 seconds is a nice range. Once we have settled on a time window, the first thing we want to  to do is to find the first spike that occured so long after the stimulus presentation began, that we can already collect the first stimulus portion of the desired size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START CODE HERE###\n",
    "window = 15\n",
    "for spike in spikes:\n",
    "    if ttls[window] < spike:\n",
    "        spike_idx = np.where(spikes == spike)[0][0]\n",
    "        break\n",
    "    else:\n",
    "        pass\n",
    "###FINISH CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know with which spike to begin with, let's initialize the variable that will store the stimulus portions preceding each spike:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_matrix = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to take all the spikes one by one (i.e., their timestamps) and take the corresponding stimulus portion preceding it, starting with the stimulus value at the instant immediately before the occurrence of the spike and stretching back by the value of the window previously defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while spike_idx < len(spikes):\n",
    "    \n",
    "    idx = np.abs(ttls - spikes[spike_idx]).argmin()\n",
    "    if ttls[idx] < spikes[spike_idx]:  \n",
    "        stim_vect = stim_rand_nums[((idx+1)-window):idx+1]\n",
    "    else:\n",
    "        stim_vect = stim_rand_nums[(idx-window):idx]\n",
    "    \n",
    "    stim_matrix.append(stim_vect)\n",
    "    spike_idx += 1\n",
    "    \n",
    "stim_matrix = np.asarray(stim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the STA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_stim = np.sum(stim_matrix, axis = 0)\n",
    "sta = average_stim/len(stim_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first plot the STA alone and see what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plt(sta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add labels and an adequate x axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START CODE HERE###\n",
    "time_limit_past = -avg_diff*window\n",
    "x_ax = np.linspace(time_limit_past, 0, num = len(sta))\n",
    "plt.plot(x_ax,sta)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Contrast')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
