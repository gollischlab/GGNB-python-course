{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c23736-a749-43aa-8c68-d69cd1556039",
   "metadata": {},
   "source": [
    "# Project 2: The Linear-Nonlinear Model\n",
    "\n",
    "Over the last two and a half days, you've learned how to analyze spike trains recorded under visual stimulation and also how to calculate the spike-triggered average (STA). As a final project in this course, you will turn to a very common modelling tool used in sensory systems neuroscience, the linear-nonlinear (LN) model.\n",
    "\n",
    "The LN model provides a simple way to predict a neuron's response to novel stimuli. At its core, the model assumes that the more similar a stimulus is to the cell's STA, the more the cell will fire. The similarity measure is a **linear** mathematical operation called a *convolution*, and the relationship between the result of the convolution and the cell's spiking output is **non-linear**. This combination of **linear + non-linear** is the reason the LN model is called the way it is called.\n",
    "\n",
    "This brings the LN model down to three steps:\n",
    "\n",
    "- compute the cell's STA\n",
    "- compute the convolution between the receptive field and the stimulus\n",
    "- find / fit the non-linear relationship between the convolution output and the firing rate\n",
    "\n",
    "At the end of this project, you'll be able to use the LN model to predict the responses of retinal ganglion cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06c6da-36ba-4baa-905e-cdb8bd1970d5",
   "metadata": {},
   "source": [
    "Let's begin by importing the required packages and defining some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c03d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.rc={'figure.figsize': (12, 6), 'font.size': 14 }\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import pearsonr\n",
    "from numpy import load\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e34f8-3287-446c-ae6f-edd54b608551",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HELPER FUNCTIONS ###\n",
    "# Please run this cell #\n",
    "# before starting with #\n",
    "#     the notebook     #\n",
    "########################\n",
    "\n",
    "\n",
    "def plot_rasters(\n",
    "    response_matrix: np.ndarray,\n",
    "    ax: plt.Axes,\n",
    "    sampling_rate: float,\n",
    "    **kwargs\n",
    "):\n",
    "    for t, trial in enumerate(response_matrix):\n",
    "        spike_list = []\n",
    "        for c, spike_count in enumerate(trial):\n",
    "            if spike_count > 0:\n",
    "                spike_list.extend((np.random.random(size=spike_count) + c).tolist())\n",
    "\n",
    "        if spike_list:\n",
    "            ax.plot(\n",
    "                np.array(spike_list) / sampling_rate,\n",
    "                [1 + t] * len(spike_list),\n",
    "                **kwargs\n",
    "            )\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fe1d83-e5c8-49a8-b43e-5fb78b7ade1a",
   "metadata": {},
   "source": [
    "Earlier today, you learned how to compute the STA for a cell given the cell's response to a certain stimulus. This means **you've already implemented the first step of the LN model!** This also means we'll be able to re-use some of the functions we wrote earlier. These have been carried over and defined for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e85399-403a-49b5-ad81-675b8cfeb60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sta(\n",
    "    spike_times_array,\n",
    "    stimulus_array,\n",
    "    pulses_array, \n",
    "    training_frames,\n",
    "    test_frames,\n",
    "    past_frames,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute a cell's spike-triggered average (STA) given it's responses to a visual stimulus.\n",
    "    \"\"\"\n",
    "    # reshape the stimulus and pulses using the training_frames and test_frames\n",
    "    stimulus_reshaped, pulses_reshaped = get_reshaped_stimulus_and_pulses(\n",
    "        stimulus_array,\n",
    "        pulses_array,\n",
    "        training_frames,\n",
    "        test_frames\n",
    "    )\n",
    "    \n",
    "    # select only those spikes which occur during the stimulus presentation\n",
    "    spikes_in_stimulus = spike_times_array[  # select...\n",
    "        (spike_times_array > pulses_reshaped.ravel()[0]) &  # ... all spikes after the first pulse\n",
    "        (spike_times_array < pulses_reshaped.ravel()[-1])  # ... and all spikes before the last pulse\n",
    "    ]\n",
    "    \n",
    "    # bin the spike train using the reshaped pulses\n",
    "    spikes_binned = compute_binned_spikes(\n",
    "        spikes_in_stimulus,\n",
    "        pulses_reshaped\n",
    "    )\n",
    "    \n",
    "    # reshape the binned spikes to the same shape as reshaped_pulses\n",
    "    spikes_in_trials = np.reshape(spikes_binned, reshaped_pulses.shape)\n",
    "    \n",
    "    # split spikes into training and test\n",
    "    training_spikes, _ = split_into_two(\n",
    "        spikes_in_trials,\n",
    "        training_frames\n",
    "    )\n",
    "    \n",
    "    # split stimulus into training and test\n",
    "    training_stimulus, _ = split_into_two(\n",
    "        stimulus_reshaped,\n",
    "        training_frames\n",
    "    )\n",
    "    \n",
    "    # get stimulus snippets past_frames before each spike\n",
    "    stimulus_snippets = get_stimulus_stack(\n",
    "        training_spikes,\n",
    "        training_stimulus,\n",
    "        past_frames\n",
    "    )\n",
    "    \n",
    "    # average over the stimulus snippets\n",
    "    sta = stimulus_snippets.mean(axis=0)\n",
    "    \n",
    "    return sta\n",
    "\n",
    "\n",
    "def get_stimulus_stack(training_spikes_array, training_stimulus, past_frames):\n",
    "    \"\"\"\n",
    "    Extract stimulus values before each spike in the training set, ignoring\n",
    "    the first past_frames bins.\n",
    "    \"\"\"\n",
    "    snippets = []  # create an empty list\n",
    "    \n",
    "    for t, trial in enumerate(training_spikes_array):  # loop over trials\n",
    "        for b, bin_count in enumerate(trial):  # loop over bins in trial\n",
    "            # only for bins after first past_frames frames\n",
    "            if (b + 1 >= past_frames) \\\n",
    "               and (bin_count > 0):  # and only for bins which have at least 1 spike\n",
    "                snippet = training_stimulus[\n",
    "                    t, b + 1 - past_frames:b + 1\n",
    "                ]  # cut out past_frames frames before the spike from the stimulus\n",
    "                for i in range(bin_count):  # append once to list for every spike in bin\n",
    "                    snippets.append(snippet)\n",
    "    \n",
    "    return np.array(snippets)  # return a numpy array\n",
    "\n",
    "\n",
    "def compute_binned_spikes(spike_times_array, reshaped_pulses_array):\n",
    "    \"\"\"\n",
    "    Bin spikes according to the bin edges defined by the pulses.\n",
    "    \"\"\"\n",
    "    binned_spike_array = np.bincount(\n",
    "        np.digitize(\n",
    "            x=spike_times_array,\n",
    "            bins=reshaped_pulses_array.ravel(),\n",
    "        ) - 1,  # important to make sure the bin ids of the spikes align with the stimulus\n",
    "        minlength=reshaped_pulses.size\n",
    "    )\n",
    "    \n",
    "    return binned_spike_array\n",
    "\n",
    "\n",
    "def split_into_two(two_dimensional_array, split_id):\n",
    "    \"\"\"\n",
    "    Split the input 2d-array along its second dimension into two sets at split_id.\n",
    "    \"\"\"\n",
    "    first_array = two_dimensional_array[:, :split_id]\n",
    "    second_array = two_dimensional_array[:, split_id:]\n",
    "    \n",
    "    return first_array, second_array\n",
    "\n",
    "\n",
    "def get_reshaped_stimulus_and_pulses(stimulus_array, pulses_array, training_frames, test_frames):\n",
    "    \"\"\"\n",
    "    Return the stimulus and pulses arrays reshaped to (trials x frames).\n",
    "    \"\"\"    \n",
    "    # compute the total number of trials in the experiment\n",
    "    frames_per_trial = training_frames + test_frames\n",
    "    total_trials = int(np.floor(pulses_array.size / frames_per_trial))\n",
    "    \n",
    "    # truncate stimulus and pulses to match the total number of complete trials\n",
    "    pulses_array = pulses_array[:total_trials * frames_per_trial]\n",
    "    stimulus_array = stimulus_array[:total_trials * frames_per_trial]\n",
    "    \n",
    "    # reshape stimulus and pulses\n",
    "    pulses_reshaped = np.reshape(pulses_array, (total_trials, frames_per_trial))\n",
    "    stimulus_reshaped = np.reshape(stimulus_array, (total_trials, frames_per_trial))\n",
    "    \n",
    "    return stimulus_reshaped, pulses_reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a64417-e080-4628-9f90-1024ae7dbfb9",
   "metadata": {},
   "source": [
    "# 1 - The stimulus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d86894-1467-4b9e-b16d-854c2b0c1c60",
   "metadata": {},
   "source": [
    "For this project, you will work with the same stimulus that you worked with this morning. As a quick recap, the full-field flicker consists of a screen-wide presentation of contrast levels that change with a given frequency (here 75Hz). The contrast value of each presentation is calculated from a number that's been drawn from a Gaussian distribution of mean zero and standard deviation 0.3, with positive values representing brighter presentations, and vice-versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a862099-798d-4210-b5d0-81c446a68daa",
   "metadata": {},
   "source": [
    "This is what it looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa270b95-9de6-46dc-bba5-c525aeb2f869",
   "metadata": {},
   "source": [
    "<center><img src=\"images/fff.gif\" width=\"200\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762ec2a9-2a8b-48cb-a176-d10470cc0160",
   "metadata": {},
   "source": [
    "The stimulus is composed of a **training set** and a **test set**, each containing a sequence of contrast values. The values in the training set are completely random and **do not repeat**, whereas those in the test set **repeat across across trials**. The test set is repeated in every trial to account for any variability, for eg. from experimental noise, that may arise in the cell's responses. \n",
    "\n",
    "The model will be evaluated on the average response of the cell to the test stimulus across trials. This also means you'll be making use of the test set in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe15e562-4061-48f4-adc1-fd2558cbbb6d",
   "metadata": {},
   "source": [
    "<p><center><img src=\"images/FFFstimstructure.png\" width=\"600\" height=\"400\"></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d5b9b-391e-4be9-a339-337f10e93aa0",
   "metadata": {},
   "source": [
    "# 2 - Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a25854-4fc4-49df-9db4-ac544782de2f",
   "metadata": {},
   "source": [
    "To begin with, let us load the stimulus and pulses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a865d-ab91-4eb1-9a4d-be8a2ab1187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulses_filepath = 'data_LN_model/frametimes_fullfieldnoise.txt'\n",
    "pulses = np.loadtxt(pulses_filepath)\n",
    "\n",
    "## Each pulse marks a change in stimulus presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc17f0e-6729-4e46-8f67-1a4aaf40d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_filepath = 'data_LN_model/stimulus_fullfieldnoise.txt'\n",
    "stimulus = np.loadtxt(stimulus_filepath)\n",
    "\n",
    "## Each value is a contrast value of the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b082ba1a-fcce-45a2-9e61-2ccb1a252798",
   "metadata": {},
   "source": [
    "You will again start by working with a single cell. So load up the spike times for one cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d29157-8ca7-4cfc-884f-117daf732c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_filepath = 'data_LN_model/fullfieldnoise_C6.txt'\n",
    "spike_times = np.loadtxt(st_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd53b87-9bda-43ef-bda1-0ac8cc8f6fe7",
   "metadata": {},
   "source": [
    "Next, let us define some of the important variables we used earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9513e512-ab80-432c-b335-f7b1189f836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nframes_training = 1800\n",
    "nframes_test = 600\n",
    "num_past_pulses = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5921dc68-eec4-418e-a393-e4bf04a8f027",
   "metadata": {},
   "source": [
    "**Recap:** use the functions we carried over to reshape the stimulus and pulses arrays into the shape `(trials x frames)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f775120e-a2d7-4479-b1e1-daa73d1bf750",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc5fe0-506b-48aa-bfbb-1d357d5fc408",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "reshaped_stimulus, reshaped_pulses = get_reshaped_stimulus_and_pulses(\n",
    "    stimulus,\n",
    "    pulses,\n",
    "    nframes_training,\n",
    "    nframes_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63cc311-a009-44d2-a5e0-4b05ca49a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshaped_stimulus.shape)\n",
    "print(reshaped_pulses.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df492f33-6af4-4279-9934-b81d5aa3fbdc",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "(41, 2400)\n",
    "(41, 2400)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b603a262-a92a-40b2-9a23-f7a5debceadc",
   "metadata": {},
   "source": [
    "**Recap:** prepare the spike trains, by selecting spikes only those spikes relevant for the stimulus, binning them and reshaping them into trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d33ebb0-1edf-4bb8-92c3-2969b40b3042",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "stimulus_spiketimes = spike_times[  # select...\n",
    "      # ... all spikes after the first pulse\n",
    "      # ... and all spikes before the last pulse\n",
    "]\n",
    "\n",
    "binned_spikes = \n",
    "\n",
    "spikes_in_trials = \n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f0a7db-64bb-4617-8634-8e008ca99b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "stimulus_spiketimes = spike_times[  # select...\n",
    "    (spike_times > reshaped_pulses.ravel()[0]) &  # ... all spikes after the first pulse\n",
    "    (spike_times < reshaped_pulses.ravel()[-1])  # ... and all spikes before the last pulse\n",
    "]\n",
    "\n",
    "binned_spikes = compute_binned_spikes(stimulus_spiketimes, reshaped_pulses)\n",
    "\n",
    "spikes_in_trials = binned_spikes.reshape(reshaped_pulses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbf3af6-686a-472f-93aa-a7ceda4c0316",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_in_trials.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f1514-7062-4393-868d-9c91ad41c81c",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "(41, 2400)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2658e1-4ec3-4106-85cc-a79575a72222",
   "metadata": {},
   "source": [
    "Lastly, you need to divide the binned spike trains into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b946c73-7668-4a6a-95dc-676260324215",
   "metadata": {},
   "source": [
    "**Exercise:** split the binned spike trains into training and test sets\n",
    "\n",
    "*Hint:* you can use functions we've already defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd7afc2-579e-4d3f-8779-4a3c7544ad5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a4645b-25fa-476d-afca-2698740254ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "training_spikes, test_spikes = split_into_two(spikes_in_trials, nframes_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5523a2ab-4631-4379-ae99-990aa1a643ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(training_spikes.shape)\n",
    "print(test_spikes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40402183-2943-40cb-91a2-f7a0c03edd74",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "(41, 1800)\n",
    "(41, 600)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386e0b7-8258-40c5-80f8-ebccf9838547",
   "metadata": {},
   "source": [
    "Before diving head long into the modelling itself, it might be worth looking at what exactly we want to be able to model / predict in the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c7677f-adf7-4a3c-9b96-c0fccda03607",
   "metadata": {},
   "source": [
    "### Visualizing the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7a0c2d-99f0-4be8-8c7c-ad0ceb6ed470",
   "metadata": {},
   "source": [
    "Each trial in the stimulus has a training and a test set. Throughout the previous session on STAs, you focused on the training set, but what you actually want to predict are the cell's responses to the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959548-b669-441c-ba69-eae0dce6cc01",
   "metadata": {},
   "source": [
    "More specifically, you want to be able to predict the **cell's average response to the test set**. So, let's calculate that quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327c9174-6887-485b-a160-e70410f021cf",
   "metadata": {},
   "source": [
    "**Exercise:** compute the average response of the cell to the test set and call it `ground_truth`\n",
    "\n",
    "*Hint:* the average here is across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1417e1bc-f695-4f64-8b69-64d6c7acd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e849e25-9351-4913-a166-86268b51a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "ground_truth = test_spikes.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cac969-d13d-4b07-ab61-9426ca1097d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ground_truth[:10])  # first ten bins\n",
    "print(ground_truth[-10:])  # last ten bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74616ea-4e52-4b6e-8363-f5147006119f",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "[0.         0.19512195 0.19512195 0.07317073 0.09756098 0.04878049\n",
    " 0.09756098 0.12195122 0.         0.04878049]\n",
    "[0.56097561 0.43902439 0.19512195 0.17073171 0.         0.04878049\n",
    " 0.04878049 0.12195122 0.02439024 0.04878049]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b15ee7-dd1f-494c-abc4-c71b2ff1bfef",
   "metadata": {},
   "source": [
    "Let's also plot this, along with the spike rasters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1f8b32-6bb7-41c5-a132-92d2cf566d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(15, 6), layout=\"constrained\", sharex=True, sharey=False, height_ratios=[3, 7])\n",
    "\n",
    "axs[0].plot(ground_truth, lw=2)\n",
    "axs[0].set_ylabel(\"spike count per bin\")\n",
    "\n",
    "axs[1] = plot_rasters(\n",
    "    response_matrix=test_spikes,\n",
    "    ax=axs[1],\n",
    "    sampling_rate=1.,\n",
    "    c='k',\n",
    "    marker=\".\",\n",
    "    markersize=1.,\n",
    "    lw=0,\n",
    ")\n",
    "axs[1].set_xlabel(\"time bins\")\n",
    "axs[1].set_ylabel(\"trials\")\n",
    "\n",
    "plt.suptitle(\"average test response for one cell\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ace89ba-eae3-4111-ae99-3175601a534b",
   "metadata": {},
   "source": [
    "This is the response of this cell to the test stimulus over 41 trials. Take a minute to examine this figure.\n",
    "\n",
    "The top plot shows the average number of spikes in each bin across all trials. The bottom plot is a raster plot of the kind you saw in the previous session, with each dot representing a spike and the rows representing trials. So, the blue trace is a result of averaging the spikes in the bottom plot across trials.\n",
    "\n",
    "Each sharp increase in the spike count in the top plot probably came right after a stimulus that the cell seemed to like! There were also periods of almost no activity (where the average spike count was zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edae08c-ca82-47e6-9051-502b24e945f5",
   "metadata": {},
   "source": [
    "At the end of this notebook, your model should be able to follow the trace in the top plot at least partially, if not completely.\n",
    "\n",
    "Let's see if this is the case!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff698c49-3bb1-47ba-890c-90ba0298a281",
   "metadata": {},
   "source": [
    "# 3 - Compute the STA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04073fd-15a6-4891-9d51-6ef74afcf8f4",
   "metadata": {},
   "source": [
    "This should be quick!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a878c8f-7431-40db-ab65-300e86f2d20e",
   "metadata": {},
   "source": [
    "**Exercise:** using the functions and variables defined earlier, calculate the STA for the cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54c4d08-8a21-4f1f-b4e8-a520ef9e2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb93284a-de3b-4486-89d1-d72a7cd0cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "sta = calculate_sta(\n",
    "    spike_times,\n",
    "    stimulus,\n",
    "    pulses,\n",
    "    nframes_training,\n",
    "    nframes_test,\n",
    "    num_past_pulses,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86df9ab-3dca-401a-9c92-960a574a572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c29ba5-e6c0-485f-9a32-2e31afd4a25d",
   "metadata": {},
   "source": [
    "**Expected output:** \n",
    "\n",
    "```\n",
    "(45,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbc7a40-b04b-4f22-983a-4a8b220fc771",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(sta[::-1], lw=2)\n",
    "ax.set_xlabel(\"time before spike (bins)\")\n",
    "ax.set_ylabel(\"contrast values\")\n",
    "ax.set_title(\"a new sta this time!\")\n",
    "ax.invert_xaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dd01b9-8f94-4a73-8dcb-51c20758bcb8",
   "metadata": {},
   "source": [
    "### Normalisation\n",
    "\n",
    "Before moving on, you will need to normalize the STA. This would ensure that the amplitude of the STA does not vary widely from cell to cell, which ensures more reliable model fitting. There are various ways in which a given signal can be normalized (the [wikipedia page](https://en.wikipedia.org/wiki/Normalization_(statistics)) is a good resource to start from). In this case, you want to have a predictable range of values for your STA irrespective of what cell you're analyzing.\n",
    "\n",
    "To this end, you must **divide** the STA by its standard deviation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388b68d9-237f-417f-8e07-80e7bdaa4c91",
   "metadata": {},
   "source": [
    "**Exercise:** divide the STA by it's standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693ec0c0-944b-45ac-8770-c00f38b8d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4191f3-863d-4702-8645-7504bafae8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "sta /= sta.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124117f1-ad87-4ae0-b1ef-a4f4ebe365af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sta.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa1d7f7-ca30-4cb0-9eeb-32d23227659a",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d23b7f9-ba20-478b-bfbe-1876a1ecd98d",
   "metadata": {},
   "source": [
    "The normalization ensures that the standard deviation of the STA is 1.0!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf9b9b1-aed4-4fd9-afa0-502a7bc2219e",
   "metadata": {},
   "source": [
    "We are now ready to tackle convolutions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6cde6f-1875-40a0-a45d-1543fb574ecf",
   "metadata": {},
   "source": [
    "# 4 - Convolve the stimulus with the STA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c290e4a8-8c45-4ac3-a5f0-de9428be29a3",
   "metadata": {},
   "source": [
    "### What are convolutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53cdd82-2744-415d-a710-20cf70b6e7aa",
   "metadata": {},
   "source": [
    "Convolution is a mathematical operation that combines two functions to produce a third function. In the context of time-series analysis, convolution allows us to express the relationship between two signals in terms of their overlap.\n",
    "\n",
    "Given two time-series signals, let's call them **signal** and **kernel**, the convolution of these signals is calculated by sliding the kernel across the signal and multiplying the corresponding values at each position, then summing up the results. This sliding operation effectively measures the similarity between the signals at different time points.\n",
    "\n",
    "Convolution is widely used in various fields, including signal processing, image processing, and machine learning. It can be utilized for tasks such as filtering, feature extraction, and pattern recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e71f1-9c4d-488e-ad9b-113c14b880bd",
   "metadata": {},
   "source": [
    "### Example: convolution of two signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5521b941-97a9-4470-9d7e-cc343288aa8f",
   "metadata": {},
   "source": [
    "Consider the following graphic:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7130781d-c771-4064-aaec-f3e1c62e4413",
   "metadata": {},
   "source": [
    "<center><img src=\"../images/convolution.gif\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad429f4-2faf-4b73-838d-d37719bc793f",
   "metadata": {},
   "source": [
    "The red curve in the top plot is the **signal** and the green curve sliding across the plot is the **kernel**. The bottom plot shows the result of convolution as the kernel slides over the signal. Each point in the bottom plot is the result of the sum of the element-wise multiplication of the kernel with the signal it overlaps with. As a result, the peak of the triangle corresponds to the point where both the kernel and the signal completely overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2926672a-bac2-4309-8773-3c873a8fd815",
   "metadata": {},
   "source": [
    "### Convolving the stimulus with the STA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2792b54-151d-4bd0-a30c-4751a6e65c1f",
   "metadata": {},
   "source": [
    "In our case, the **signal** is the stimulus and the **kernel** is the STA. The result of their convolution will yield a third signal in which higher values indicate stimuli that resembled the STA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4ef5d6-0538-487c-9833-6faf5f5da67a",
   "metadata": {},
   "source": [
    "Since you want to use the training set in the stimulus to train the model, and the test set only to evaluate the model performance, you must first split the `reshaped_stimulus` into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4571e8e-a119-45e3-994f-863123b9ea74",
   "metadata": {},
   "source": [
    "**Exercise:** split the `reshaped_stimulus` into training and test sets, just like you did for the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271b523-a4b9-415b-9d3f-3f5df0731a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e97cf0-38ba-46ef-9178-bc43fbc0ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "training_stimulus, test_stimulus = split_into_two(reshaped_stimulus, nframes_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e933c05-7aed-4638-89d8-d9f44cfb4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_stimulus.shape)\n",
    "print(test_stimulus.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7cc33-0dce-4f36-9012-604050d613e0",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "(41, 1800)\n",
    "(41, 600)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0aaecc-8cfa-4d6e-8603-462fd601fc2f",
   "metadata": {},
   "source": [
    "Now, to the convolution itself!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cdd889-197b-4980-8e1d-1e954bbd6762",
   "metadata": {},
   "source": [
    "**CAUTION:** the convention is that the STA must have it's elements ordered **backwards from the time of the spike**. So, you must remember to **flip the kernel (STA) before feeding it to the numpy `convolve` function**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee71e31e-0a6c-4865-b1dd-4c583981f85a",
   "metadata": {},
   "source": [
    "**Exercise:** complete the function that convolves the stimulus with the STA\n",
    "\n",
    "*Hint 1:* each trial should be convolved separately (why?), so make sure you loop over the trials\n",
    "\n",
    "*Hint 2:* use `np.convolve` to do the convolution using the mode \"valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1689d38-de71-4d4f-aa63-2933927103b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_stimulus_with_sta(stimulus_array, cell_sta):\n",
    "    \"\"\"\n",
    "    Use np.convolve to compute the trial-by-trial convolution\n",
    "    of the visual stimulus with a cell's spike-triggered avg.\n",
    "    \"\"\"\n",
    "    conv_list = []\n",
    "    \n",
    "    ## START CODE HERE ##\n",
    "    \n",
    "    \n",
    "        \n",
    "    ## END CODE HERE ##\n",
    "    \n",
    "    return np.array(conv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c025e072-265b-43a8-a9c5-3ab01bb24cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_stimulus_with_sta(stimulus_array, cell_sta):\n",
    "    \"\"\"\n",
    "    Use np.convolve to compute the trial-by-trial convolution\n",
    "    of the visual stimulus with a cell's spike-triggered avg.\n",
    "    \"\"\"\n",
    "    conv_list = []\n",
    "    \n",
    "    ## START CODE HERE ##\n",
    "    \n",
    "    for trial in stimulus_array:\n",
    "        conv = np.convolve(trial, cell_sta[::-1], mode=\"valid\")\n",
    "        conv_list.append(conv)\n",
    "        \n",
    "    ## END CODE HERE ##\n",
    "    \n",
    "    return np.array(conv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74322582-d44f-408c-9eeb-127381652385",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved_signal = convolve_stimulus_with_sta(training_stimulus, sta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a62af51-dbf7-4a9e-ba07-e7f0c99796e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(convolved_signal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38bbc60-f846-4f70-b1d6-dfa00b36ca72",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "(41, 1756)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e06101-ffa9-4278-a3d2-365e0220da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(convolved_signal[0, :10]) # first ten bins\n",
    "print(convolved_signal[-1, -10:]) # last ten bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe25cd-b75e-4dc0-a1fa-27eb17de0140",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "[ 0.09504644  0.29837892  1.8295958   6.2266448  10.72876016 15.24241819\n",
    " 16.13379787 12.77382108  3.21070508 -6.08765853]\n",
    "[ 7.99098308 11.35632167  8.99469585  6.02971824  2.90366299  3.886229\n",
    "  4.0111409   5.11022628  2.89511875  1.94620747]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b13646-10de-4de6-bc8d-ae99932db123",
   "metadata": {},
   "source": [
    "Now, feel free to plot and explore what the convolved stimulus looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59c4a96-6cc6-4a06-8d40-75e960662b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6), layout=\"constrained\")\n",
    "ax.plot(convolved_signal[0], lw=3)\n",
    "ax.set_xlabel(\"time bins\")\n",
    "ax.set_title(\"Convolved signal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec71f033-a613-4ee7-b023-fa461c32dc95",
   "metadata": {},
   "source": [
    "**Questions:** \n",
    "\n",
    "* why does the convolved signal have fewer time bins than the stimulus?\n",
    "* is there a way to compute number of time bins in the convolved signal given a stimulus and an STA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e6cd54-69ae-4c1b-a750-e52257db6dda",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5 - Relate the convolution to spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73922419-cb28-4af2-98c2-91521c3d85bb",
   "metadata": {},
   "source": [
    "Congratulations, you have the next piece of the LN puzzle: the convolved signal!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3915a9-c331-427d-b0d0-8ba4a5b5a3a5",
   "metadata": {},
   "source": [
    "You now need to figure out the relationship between the output of the convolution and the firing response of the cell. According to our assumptions, whenever the output of the convolution is large, the firing response of the cell is also large. How would you go about verifying this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe89569-6f8a-430b-a6fc-35f8f9add04a",
   "metadata": {},
   "source": [
    "Well, you want to find out how some change in the value of the convolved signal is translated to a change in the firing response of the cell. Since both the convolved signal and the spike train are binned in the same way, you could simply plot one against the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1c43bc-4505-411f-9d9d-c2fde34bf37f",
   "metadata": {},
   "source": [
    "**But do the `convolved_signal` and `training_spikes` have the same dimensions?**\n",
    "\n",
    "No! Although they have the same number of trials, they have different numbers of time bins. More specifically, **the first `num_past_pulses - 1` bins of `convolved_signal` are truncated**. This is a result of the convolution operation. We don't have time to go into the math here, but you're encouraged to read up about it, for eg [here](https://towardsdatascience.com/convolutions-in-one-dimension-using-python-54d743f18063)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d7fe50-7375-47d6-930f-2d93e955cc05",
   "metadata": {},
   "source": [
    "Okay, now try to plot the relationship between the `convolved_signal` and the `training_spikes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e870e336-02f0-4b07-a585-bec515b3fdd0",
   "metadata": {},
   "source": [
    "**Exercise:** complete the code below to plot values of the convolved signal on the x-axis and the corresponding spike counts from the training set on the y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95864464-4cef-46a9-a8dd-82397b1fd0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "\n",
    "## COMPLETE THE FOLLOWING LINE ##\n",
    "\n",
    "ax.scatter(      ,        , c=\"tab:green\", s=2)\n",
    "\n",
    "ax.set_xlabel(\"Values in the Convolved Signal\")\n",
    "ax.set_ylabel(\"Spike Count\")\n",
    "ax.set_title(\"Relationship between the convolved signal and spike counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615aa72-d652-4eb2-869e-130804c1a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "\n",
    "ax.scatter(convolved_signal.ravel(), training_spikes[:, num_past_pulses-1:].ravel(), c=\"tab:green\", s=2)\n",
    "\n",
    "ax.set_xlabel(\"Values in the Convolved Signal\")\n",
    "ax.set_ylabel(\"Spike Count\")\n",
    "ax.set_title(\"Relationship between the convolved signal and spike counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42563e81-920a-4940-91a0-ea532f2ed62f",
   "metadata": {},
   "source": [
    "This... is not very helpful, is it? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ec63d-6bbe-4ff7-94d0-fa7aaff9a37c",
   "metadata": {},
   "source": [
    "When the values of the convolved signal are small, the output spike count is also small, and vice-versa. The problem here is that the **spike counts are whole numbers** (0, 1, 2, 3...), so even for a large variation in the convolution output, the spike count only jumps between neighbouring values. Moreover, the cell is not entirely reliable - for the same value of a convolved signal, it could potentially have very different firing responses. What you would ideally like to have is a **smoother transition over the range of spike counts for any change in the convolution output**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbecc660-904e-4166-a2c6-3a622f19e1ba",
   "metadata": {},
   "source": [
    "### How do you fix this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4547750-8e80-4b89-9756-b2642d4ad5fc",
   "metadata": {},
   "source": [
    "**By fitting a curve!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2718e2-5be5-4ab4-ab51-a2de24929481",
   "metadata": {},
   "source": [
    "(Well, there is a lot more nuance to it than this, but for the illustrative and educative purposes of this course, fitting a nice curve to this plot should suffice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9535a0-8218-460e-a69e-e4fad46ed6dc",
   "metadata": {},
   "source": [
    "# 6 - Fit a Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d91a3eb-ba1e-4dd0-a61d-04719baca912",
   "metadata": {},
   "source": [
    "To fit a curve, you first need to decide what sort of a curve you'd like to fit. There are more than a few families of curves to choose from (and if you're more mathematically inclined, you could even come up with your own little curve that could work here). However, to keep things simple, you'll start with a simple **parametrized exponential**, the formula for which would be:\n",
    "\n",
    "$$\n",
    "f(x) = a \\cdot \\exp(b \\cdot x + c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a189bf3-b007-4018-9134-640ff31163d1",
   "metadata": {},
   "source": [
    "This is in effect just an exponential, the additional parameters allow us to fit it to our data a bit better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60128b9f-da6b-486f-906a-7122d5d4eebc",
   "metadata": {},
   "source": [
    "Go ahead and define this in a function!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97e2c2c-76b3-4f80-b05c-ac9c1a4dc051",
   "metadata": {},
   "source": [
    "**Exercise:** define a parametrized exponential function, with the first input argument as `x` and the subsequent ones being `a`, `b` and `c`. **The order of arguments is important here**. Internally, make use of the fact that the input `x` will always be a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e17dab-e472-46ed-a53c-3741dab394be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "def exponential(   ):\n",
    "    \n",
    "    return \n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9790ca-49f8-4485-910a-08c008acfdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "def exponential(x, a, b, c):\n",
    "    \"\"\"\n",
    "    A parametrized exponential.\n",
    "    \"\"\"\n",
    "    return a * np.exp(b * x + c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d305b4-78b8-4ee0-9c88-c77a5ddba083",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exponential(np.arange(10), 0.5, 0.5, -0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84bdb7-bfa4-49ae-a4c7-6b60cf12e26c",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "[ 0.30326533  0.5         0.82436064  1.35914091  2.24084454  3.69452805\n",
    "  6.09124698 10.04276846 16.55772598 27.29907502]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c5a4f-8962-4d35-bd7c-665df061947a",
   "metadata": {},
   "source": [
    "Fantastic! Now you have a function you can fit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6532dd-1a61-4fe6-8f10-5db146855aae",
   "metadata": {},
   "source": [
    "For the fitting itself, we'll be using the function `curve_fit` provided by the `optimize` module of the package `scipy`. This has already been imported in the notebook, but you're encouraged to go through the documentation for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7c5377-b114-4cbc-995a-fafa2edc01df",
   "metadata": {},
   "source": [
    "### Curve fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d558411-cb2a-43b2-9a72-a92154413aec",
   "metadata": {},
   "source": [
    "`curve_fit` takes as input:\n",
    "\n",
    "1. the function you want to fit, \n",
    "2. the x axis values and the y axis values from our data, \n",
    "3. bounds we'd like to enforce on our parameters, and\n",
    "4. an initial set of parameters\n",
    "\n",
    "and returns the set of optimal parameters (in the order of their input into the function)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1702cc0-36df-472f-9df4-fbba40976fc1",
   "metadata": {},
   "source": [
    "In the parametrized exponential function, we can be relatively certain that the output of the function needs to be positive. This sets a lower bound on `a` at `0`. However, none of the other parameters have an obvious bound to them, so it's best to provide no other bound to the fitting algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab386522-6889-48f7-9443-5b092b902cb8",
   "metadata": {},
   "source": [
    "Choosing the right set of initial parameters is an art unto itself, and is probably worth spending more time on than we have in this course. For now, a reasonable set of initial parameters have been chosen for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2791f2ca-d7cf-45c2-94ae-be0bbf199733",
   "metadata": {},
   "source": [
    "**Exercise:** fill out the missing arguments to the `curve_fit` function\n",
    "\n",
    "*Hint 1:* the function argument should be without parantheses\n",
    "\n",
    "*Hint 2:* remember to .`ravel()` the x- and y-axis values\n",
    "\n",
    "*Hint 3:* make sure the x- and y-axis values have the same shape (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9a629-0bcb-4d46-a1df-5d314ab042fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILL IN THE MISSING ARGUMENTS ##\n",
    "\n",
    "optimal_parameters, _ = curve_fit(\n",
    "    f=,  # the function you'd like to fit\n",
    "    xdata=  # x axis values\n",
    "    ydata=  # y axis values\n",
    "    p0=[2.0, 0.5, -1.5],  # initial parameters\n",
    "    bounds=([0, -np.inf, -np.inf], np.inf),  # bounds\n",
    "    maxfev=4000,  # just making sure the algorithm converges, hehe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d706233-9581-4c5c-9ff6-08cd0fec6a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "optimal_parameters, _ = curve_fit(\n",
    "    f=exponential,  # the function we'd like to fit\n",
    "    xdata=convolved_signal.ravel(),  # x axis values\n",
    "    ydata=training_spikes[:, num_past_pulses - 1:].ravel(),  # y axis values\n",
    "    p0=[2.0, 0.5, -3.0],  # initial parameters\n",
    "    bounds=([0, -np.inf, -np.inf], np.inf),  # bounds\n",
    "    maxfev=4000,  # just making sure the algorithm converges, hehe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00445c-880e-458d-859c-5a9f762aa212",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede33ed4-6e06-4101-b8f1-d6b441d7ef39",
   "metadata": {},
   "source": [
    "The exact fit parameters will be different for everyone, so there is only one way to check if the fit makes any sense: by plotting it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e4aa06-685c-452a-88e0-e13acb65b07c",
   "metadata": {},
   "source": [
    "What you want to plot is the output of the exponential function for a set of x-axis values, given the optimal parameters. In the next cell, a set of `x_values` is defined spanning the range of values you see in the data. \n",
    "\n",
    "\n",
    "What you must do is compute the exponential for those `x_values` using the optimal parameters you just calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf154a0-7fcf-43db-99a0-c502e36e7919",
   "metadata": {},
   "source": [
    "**Exercise:** complete the code to compute `y_fit`, feeding `x_values` and `optimal_parameters` as input to the exponential function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6073804-b54c-4337-af7d-d1f119a9971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = np.linspace(\n",
    "    start=np.floor(convolved_signal.min()),\n",
    "    stop=np.ceil(convolved_signal.max()),\n",
    "    num=51\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a63200-248b-439b-9e8f-227b5efcf948",
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPLETE THE FOLLOWING LINE ##\n",
    "\n",
    "y_fit = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e637ad9-e6a7-4f61-b93f-0d4a178b1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "y_fit = exponential(x_values, *optimal_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505ccf50-b0d1-46c9-809b-c1cac8d5a497",
   "metadata": {},
   "source": [
    "Time to see the plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e13e73-c0ad-4167-8469-54d34d441029",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "ax.scatter(convolved_signal.ravel(), training_spikes[:, num_past_pulses-1:].ravel(), c=\"tab:green\", s=2)\n",
    "ax.plot(x_values, y_fit, lw=3, c=\"tab:orange\", label=\"exp. fit\")\n",
    "ax.set_xlabel(\"Values in the Convolved Signal\")\n",
    "ax.set_ylabel(\"Spike Count\")\n",
    "ax.set_title(\"Relationship between the convolved signal and spike counts\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee538ae0-6642-4bac-9c0b-75b7a297da71",
   "metadata": {},
   "source": [
    "Excellent!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff82bbbb-e19c-4599-820a-1f21d095dda7",
   "metadata": {},
   "source": [
    "You now have a smooth function that translates changes in the convolution output to changes in spiking activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b07dc67-e2ac-4070-a141-5971c7e0f481",
   "metadata": {},
   "source": [
    "It's time to predict!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9565c84-29b1-40dd-8491-6d18e2d54c47",
   "metadata": {},
   "source": [
    "# 7 - Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3946b885-ebbe-4bee-bd43-182b37cfc314",
   "metadata": {},
   "source": [
    "Prediction is the quickest part of the model. What you need to do is as follows:\n",
    "\n",
    "1. convolve the test stimulus with the STA to get a `test_convolved` signal\n",
    "2. pass the values of the `test_convolved` signal to the exponential function, along with the optimal parameters you computed, to get predicted responses\n",
    "3. compare and plot the cell's ground truth response with the predicted response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc71017-6a4a-41f5-96da-4e351764a206",
   "metadata": {},
   "source": [
    "So let's get to it - let's see if you can do this with minimal assistance..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2ab0a-7f12-41c1-895f-7641313bb540",
   "metadata": {},
   "source": [
    "**Exercise:** convolve the test stimulus with the cell's STA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405bd4c3-5420-4dcc-b5de-24d654680fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb48101f-f6dc-4c82-8ab4-4fbb26da71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "test_convolved = convolve_stimulus_with_sta(test_stimulus[:1, :], sta)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8678356f-c9f6-44c1-a183-7136d8bf83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_convolved[:10]) # first ten bins\n",
    "print(test_convolved[-10:]) # last ten bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4eaedb-f0bd-4f56-949b-d91ebec041f8",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "[ 9.83264254 11.59203491 11.18314166  7.05552873  4.8746515   0.88349744\n",
    " -2.08094665 -0.36610227  2.49119166  6.88311984]\n",
    "[13.84409797 14.3960606  12.22459318  8.37844131  5.54077512  3.10056181\n",
    "  4.43419756  4.72008878  3.45400087  0.59254138]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baf68d7-750f-430f-9d21-da9c1275eeab",
   "metadata": {},
   "source": [
    "**Exercise:** compute the predicted responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c9cab9-b125-4d1f-8807-aa057d2b2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66fea7-212a-47e3-8b45-43667ae18b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "y_predicted = exponential(test_convolved, *optimal_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c97f1ba-dd56-4b1b-9934-86bf7e9c2498",
   "metadata": {},
   "source": [
    "Amazing! Now it's time to see if what you predicted looks anything like the ground truth!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2bd402-4e56-4932-9d03-93ef0915fb81",
   "metadata": {},
   "source": [
    "**Drumroll...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d9c3c-5844-4099-bf85-424fbe7ffcca",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501066a8-01c4-4b68-b37f-6d4f0af324a8",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e5810c-b351-43c9-8515-d7c75e085a7b",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b148fe47-7e99-4cbe-b076-c0ddfa6e70e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 4), layout=\"constrained\")\n",
    "ax.plot(ground_truth[num_past_pulses-1:], lw=3, c=\"tab:blue\", label=\"ground truth\") \n",
    "## NOTE: we truncated the ground truth above\n",
    "\n",
    "ax.plot(y_predicted, lw=3, c=\"tab:red\", label=\"predicted\")\n",
    "ax.set_xlabel(\"time bins\")\n",
    "ax.set_ylabel(\"spike count per bin\")\n",
    "ax.set_title(\"ground truth vs prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed81ad3f-0ea6-4576-b37e-5d9685a46e89",
   "metadata": {},
   "source": [
    "**Ta Da!!!**\n",
    "\n",
    "Surprised? Disappointed?\n",
    "\n",
    "Well, clearly, the predicted traces do follow the \"tendency\" of the ground truth, but don't quite manage to find the same amplitude in the peaks, nor find the quietness of the flats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dbb4b8-5a45-4ec3-aaa9-3e056b1ee4c4",
   "metadata": {},
   "source": [
    "You can quantify the similarity between the predicted traces and ground truth using the **Pearson's correlation coefficient**, or **Pearson's R**. For this, you will use another `scipy` function called `pearsonr`, that's also been imported for you already."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a052f-b56b-4045-b98d-f50b35844151",
   "metadata": {},
   "source": [
    "**Exercise:** compute the Pearson's R between the predicted responses and ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e7f35e-a475-4e2c-98e5-9cfc0272d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0e6e7e-46d1-49b7-9874-4463219f1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "r_value = pearsonr(ground_truth[num_past_pulses-1:], y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33bc35-64b9-46ca-8880-2d172a56cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_value)  # THIS RESULT MAY DIFFER FOR YOU, BUT IT SHOULD BE CLOSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5253a11c-e131-49d8-a477-a8b160ca6f12",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "PearsonRResult(statistic=0.8343205916332544, pvalue=2.1298152908910366e-145)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3dba29-505b-4394-84a1-88ccda3de495",
   "metadata": {},
   "source": [
    "Well, maybe that is surprising for you? The **correlation coefficient between the two signals is pretty high**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f133d15f-a1ab-474b-9b13-fbac921495dd",
   "metadata": {},
   "source": [
    "You might argue that this statistic is misleading, and you wouldn't be entirely wrong. The **correlation coefficient is sensitive to the location of the peaks and troughs in two signals, but not so much to their relative amplitudes**. As a result, our predicted trace gets a pretty high r-value, even though it clearly falls short of predicting the cell's peaks of activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e325e07-6ee0-4246-87e5-e5f527ad7d3a",
   "metadata": {},
   "source": [
    "This means that it's **important to look at the actual traces and not just the statistics** to determine how good or bad a model is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0618ccc6-f54b-4ca4-8327-722059400ea3",
   "metadata": {},
   "source": [
    "It also means that our current implementation of the LN model is far from perfect at predicting (at least this cell's) responses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51277c5e-dc5c-446f-a7b4-95084f664fad",
   "metadata": {},
   "source": [
    "However, we'd also like to argue that this is **already fantastic for a model which took you one day to implement with limited experience in Python programming**. Where more sophisticated models might win in better predictive power, the LN model wins in simplicity and clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5761f4-d48d-4699-bfb2-6ab246f53698",
   "metadata": {},
   "source": [
    "The last thing to do now is to apply this model to other cells and examine the differences in model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6b0fc-a303-4f65-adc0-c3474a8c77b7",
   "metadata": {},
   "source": [
    "# 8 - Multiple Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7e9a43-97c1-43c2-a826-7e05ed158cf5",
   "metadata": {},
   "source": [
    "Before you repeat this process for multiple cells, it would be best to implement a function for this. \n",
    "\n",
    "This will be a **big function**, and you'll have to implement it carefully. The function needs to have the following properties:\n",
    "\n",
    "1. It implements the LN model for a single cell\n",
    "2. It takes as input the spike times, stimuli, pulses, number of past frames for the sta, number of test and training frames, the fitting function, fit bounds and inital fit parameters\n",
    "3. It returns a **python dictionary** containing the following keys - `prediction`, `ground_truth`,`r_val`, `fit_parameters` and `sta`\n",
    "4. Internally, it repeats all the steps from the `calculate_sta` function. Ideally we would use the calculate_sta function directly, but many of the steps used in that function need to be repeated here as well. So feel free to copy the internals of the `calculate_sta` function and paste them inside this function, taking care that you're using the right variables. (it's perfectly fine if you choose not to do this, but you'll be recalculating many of the variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ec599-1213-4215-b2a8-f415484caab6",
   "metadata": {},
   "source": [
    "**Exercise:** complete the following function that implements the LN model for a single cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c793be78-4c17-47fd-b9a7-f530a684b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECK FOR MISSING LINES IN CODE AND COMPLETE THEM ##\n",
    "\n",
    "def ln_model(\n",
    "    spike_times_array,\n",
    "    stimulus_array,\n",
    "    pulses_array, \n",
    "    training_frames,\n",
    "    test_frames,\n",
    "    past_frames,\n",
    "    fit_function,\n",
    "    fit_bounds,\n",
    "    init_params,\n",
    "):\n",
    "    # reshape the stimulus and pulses using the training_frames and test_frames\n",
    "    stimulus_reshaped, pulses_reshaped = \n",
    "    \n",
    "    # select only those spikes which occur during the stimulus presentation\n",
    "    spikes_in_stimulus = spike_times_array[  # select...\n",
    "        (   ) &  # ... all spikes after the first pulse\n",
    "        (   )  # ... and all spikes before the last pulse\n",
    "    ]\n",
    "    \n",
    "    # bin the spike train using the reshaped pulses\n",
    "    spikes_binned = \n",
    "    \n",
    "    # reshape the binned spikes to the same shape as reshaped_pulses\n",
    "    spikes_in_trials = \n",
    "    \n",
    "    # split spikes into training and test\n",
    "    training_spikes, test_spikes = \n",
    "    \n",
    "    # split stimulus into training and test\n",
    "    training_stimulus, test_stimulus = \n",
    "    \n",
    "    # get stimulus snippets past_frames before each spike\n",
    "    stimulus_snippets = \n",
    "    \n",
    "    # average over the stimulus snippets\n",
    "    sta = \n",
    "    \n",
    "    # normalize the sta\n",
    "    \n",
    "    \n",
    "    # compute the ground truth responses\n",
    "    ground_truth = \n",
    "    \n",
    "    # convolve the training stimulus with the sta\n",
    "    convolved_training = \n",
    "    # convolve the test stimulus with the sta\n",
    "    convolved_test =     \n",
    "    \n",
    "    # compute fit parameters\n",
    "    fit_parameters, _ = curve_fit(\n",
    "        f=             # the function we'd like to fit\n",
    "        xdata=         # x axis values\n",
    "        ydata=         # y axis values\n",
    "        p0=            # initial parameters\n",
    "        bounds=        # bounds\n",
    "        maxfev=4000,   # just making sure the algorithm converges, hehe\n",
    "    )\n",
    "    \n",
    "    # run the prediction on convolved_test using the fit_parameters\n",
    "    prediction = \n",
    "    \n",
    "    # compute pearson's r\n",
    "    r_val = \n",
    "    \n",
    "    # store results\n",
    "    result_dict = {\n",
    "        \"prediction\": prediction,\n",
    "        \"ground_truth\": ground_truth[past_frames-1:],\n",
    "        \"r_val\": r_val.statistic,\n",
    "        \"fit_parameters\": fit_parameters,\n",
    "        \"sta\": sta,\n",
    "    }\n",
    "    \n",
    "    return result_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886de7f1-d643-4ca9-9e49-49e8da401bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "def ln_model(\n",
    "    spike_times_array,\n",
    "    stimulus_array,\n",
    "    pulses_array, \n",
    "    training_frames,\n",
    "    test_frames,\n",
    "    past_frames,\n",
    "    fit_function,\n",
    "    fit_bounds,\n",
    "    init_params,\n",
    "):\n",
    "    # reshape the stimulus and pulses using the training_frames and test_frames\n",
    "    stimulus_reshaped, pulses_reshaped = get_reshaped_stimulus_and_pulses(\n",
    "        stimulus_array,\n",
    "        pulses_array,\n",
    "        training_frames,\n",
    "        test_frames\n",
    "    )\n",
    "    \n",
    "    # select only those spikes which occur during the stimulus presentation\n",
    "    spikes_in_stimulus = spike_times_array[  # select...\n",
    "        (spike_times_array > pulses_reshaped.ravel()[0]) &  # ... all spikes after the first pulse\n",
    "        (spike_times_array < pulses_reshaped.ravel()[-1])  # ... and all spikes before the last pulse\n",
    "    ]\n",
    "    \n",
    "    # bin the spike train using the reshaped pulses\n",
    "    spikes_binned = compute_binned_spikes(\n",
    "        spikes_in_stimulus,\n",
    "        pulses_reshaped\n",
    "    )\n",
    "    \n",
    "    # reshape the binned spikes to the same shape as reshaped_pulses\n",
    "    spikes_in_trials = np.reshape(spikes_binned, reshaped_pulses.shape)\n",
    "    \n",
    "    # split spikes into training and test\n",
    "    training_spikes, test_spikes = split_into_two(\n",
    "        spikes_in_trials,\n",
    "        training_frames\n",
    "    )\n",
    "    \n",
    "    # split stimulus into training and test\n",
    "    training_stimulus, test_stimulus = split_into_two(\n",
    "        stimulus_reshaped,\n",
    "        training_frames\n",
    "    )\n",
    "    \n",
    "    # get stimulus snippets past_frames before each spike\n",
    "    stimulus_snippets = get_stimulus_stack(\n",
    "        training_spikes,\n",
    "        training_stimulus,\n",
    "        past_frames\n",
    "    )\n",
    "    \n",
    "    # average over the stimulus snippets\n",
    "    sta = stimulus_snippets.mean(axis=0)\n",
    "    \n",
    "    # normalize the sta\n",
    "    sta /= sta.std()\n",
    "    \n",
    "    # compute the ground truth responses\n",
    "    ground_truth = test_spikes.mean(axis=0)\n",
    "    \n",
    "    # convolve the training stimulus with the sta\n",
    "    convolved_training = convolve_stimulus_with_sta(training_stimulus, sta)\n",
    "    # convolve the test stimulus with the sta\n",
    "    convolved_test = convolve_stimulus_with_sta(test_stimulus[:1, :], sta)[0]\n",
    "    \n",
    "    # compute fit parameters\n",
    "    fit_parameters, _ = curve_fit(\n",
    "        f=fit_function,  # the function we'd like to fit\n",
    "        xdata=convolved_training.ravel(),  # x axis values\n",
    "        ydata=training_spikes[:, past_frames - 1:].ravel(),  # y axis values\n",
    "        p0=init_params,  # initial parameters\n",
    "        bounds=fit_bounds,  # bounds\n",
    "        maxfev=4000,  # just making sure the algorithm converges, hehe\n",
    "    )\n",
    "    \n",
    "    # run the prediction on convolved_test using the fit_parameters\n",
    "    prediction = fit_function(convolved_test, *fit_parameters)\n",
    "    \n",
    "    # compute pearson's r\n",
    "    r_val = pearsonr(ground_truth[past_frames-1:], prediction)\n",
    "    \n",
    "    # store results\n",
    "    result_dict = {\n",
    "        \"prediction\": prediction,\n",
    "        \"ground_truth\": ground_truth[past_frames-1:],\n",
    "        \"r_val\": r_val.statistic,\n",
    "        \"fit_parameters\": fit_parameters,\n",
    "        \"sta\": sta,\n",
    "    }\n",
    "    \n",
    "    return result_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279555dc-bc51-404a-9e23-e30c5fdbb73d",
   "metadata": {},
   "source": [
    "There is no easy way to test if this function is correctly implemented, so best to run this on the all the cells and see if there are any errors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290ff3e-96b4-4346-94d6-99bdbcb02934",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "filepaths = sorted(Path('data_LN_model').glob('fullfieldnoise*.txt'))\n",
    "\n",
    "for filepath in filepaths:\n",
    "    # load spike times for each cell\n",
    "    spike_times = np.loadtxt(filepath)\n",
    "    \n",
    "    result = ln_model(\n",
    "        spike_times_array=spike_times,\n",
    "        stimulus_array=stimulus,\n",
    "        pulses_array=pulses,\n",
    "        training_frames=nframes_training,\n",
    "        test_frames=nframes_test,\n",
    "        past_frames=num_past_pulses,\n",
    "        fit_function=exponential,\n",
    "        fit_bounds=([0, -np.inf, -np.inf], np.inf),\n",
    "        init_params=[2.0, 0.5, -1.5],\n",
    "    )\n",
    "    \n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a736155-7030-4e01-9dc5-1f978bbd9be9",
   "metadata": {},
   "source": [
    "If the cell above ran without an issue, **congratulations**! You have successfully implemented the LN model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb808fa9-4cc2-462b-861b-5d7df3de13ec",
   "metadata": {},
   "source": [
    "It's now time to plot results for all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf00a3-cb33-441f-af3f-b61c5813a9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=4, ncols=2, layout=\"constrained\", sharex=True, sharey=True, figsize=(15, 15))\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    ax = axs.flat[i]\n",
    "    \n",
    "    ax.plot(result[\"ground_truth\"], lw=2, c=\"tab:blue\")\n",
    "    ax.plot(result[\"prediction\"], lw=2, c=\"tab:red\")\n",
    "    ax.set_title(f\"cell {i+1}, pearson's r: {result['r_val']:.2f}\")\n",
    "    \n",
    "    if i % 2 == 0:\n",
    "        ax.set_ylabel(\"avg. spike count\")\n",
    "    \n",
    "    if i > 5:\n",
    "        ax.set_xlabel(\"time bins\")\n",
    "\n",
    "plt.suptitle(\"LN model: ground truth (blue) vs prediction (red)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa15e5ae-d51e-42df-8973-ed556f7f3e7c",
   "metadata": {},
   "source": [
    "All together, these plots look very promising! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdc4e51-dc44-4f69-97c3-aab40478a713",
   "metadata": {},
   "source": [
    "For a model that makes very few assumptions and is easy to implement, it was able to predict the responses of these cells remarkably well! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d93a9-ab13-42ec-aeb1-1b60db26267d",
   "metadata": {},
   "source": [
    "Here's a final summary, and some notes:\n",
    "\n",
    "1. You implemented (probably) your first model that predicts the responses of retinal ganglion cells. You tested this on a full-field flicker stimulus, although there is nothing inherently preventing the model from predicting responses to other full field stimuli, assuming you have the cell's STA to begin with. \n",
    "2. In the process, you learnt how to manipulate a variety of python data structures, and we hope that you're feeling more confident with your pythonic abilities now!\n",
    "3. We deliberately did not go into how to make scientific figures in Python using matplotlib because that is a whole (and much longer) course unto itself. However, the example plots in this tutorial (and the previous ones) should have given you a good idea of how to start!\n",
    "4. We didn't always follow the best Python coding practices in this tutorial (or the others), but we encourage you to keep those in mind when writing Python code. It will help keep your code organized and efficient. For further reading, you can go through [this very nice tutorial](https://docs.python-guide.org/writing/style/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683d72e-05da-4151-b6d2-9c2327d2a919",
   "metadata": {},
   "source": [
    "# END OF TUTORIAL\n",
    "\n",
    "Everything after this will either be put into an optional section at the end, or removed entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f4670f-710b-46ac-8cbe-ea9dd5d68a2a",
   "metadata": {},
   "source": [
    "Well, by binning the convolved signal, and obtaining a plot that looks something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e6bf30-028c-4caa-b1e4-864cdee0ede2",
   "metadata": {},
   "source": [
    "<center><img src=\"images/ln_model_cartoon.jpeg\" width=\"600\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce2c5e-0c25-4d89-89d6-5781b3461e6a",
   "metadata": {},
   "source": [
    "The green dots are the same as the ones you plotted above, but each bin in the red histogram shows the **average spike count when the convolved signal values were in that bin**.\n",
    "\n",
    "It might be worth pausing for a moment and thinking about what is happening here and why this is a good idea! Feel free to ask us / discuss with us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2225a438-42de-4248-b028-e0369a53c423",
   "metadata": {},
   "source": [
    "To start with, let's define 30 bins between the smallest and the largest `convolved_signal` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb030c41-7e3a-4fd5-95f4-b37334634e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_bins = 30\n",
    "\n",
    "bin_edges = np.linspace(\n",
    "    np.floor(convolved_signal.min()), \n",
    "    np.ceil(convolved_signal.max()), \n",
    "    num=num_of_bins + 1  # since we're defining the bin edges here, and not the bins\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b7594-3910-480a-b80f-22678ff267e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e6711f-ae6f-4c6c-8f96-f722355534be",
   "metadata": {},
   "source": [
    "Next, you want a function that computes the average spike counts per bin. Go ahead and fill out the function below!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a599c1-ed3d-4f7a-9d6d-7dffbb87c314",
   "metadata": {},
   "source": [
    "**Exercise:** complete the function below which should take the convolved signal, training spikes and bin edges as input, and returns an array with the average spike counts per bin\n",
    "\n",
    "**CAUTION**: the function assumes that the `cell_response` has the same shape as `convolution`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ce055-9337-4b8c-bc15-16e4cc3bb412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_spk_cts_per_bin(\n",
    "    convolution,\n",
    "    cell_response,\n",
    "    bin_edges,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute the average response of the cell for ranges of convolved values\n",
    "    defined by the bin edges.\n",
    "    \"\"\"\n",
    "    # initialize an array to store average counts\n",
    "    avg_counts = np.zeros((bin_edges.size - 1,))\n",
    "    \n",
    "    # loop over the bin edges\n",
    "    for b, lower_edge in enumerate(bin_edges[:-1]):\n",
    "        upper_edge = bin_edges[b+1]\n",
    "        \n",
    "        ## START CODE HERE ##\n",
    "        \n",
    "        # create a numpy mask using np.where to select appropriate convolution values\n",
    "        conv_mask = np.where(\n",
    "            (convolution >= lower_edge) & \n",
    "            (convolution <  upper_edge)\n",
    "        )\n",
    "        # compute the mean response at all positions selected by the mask\n",
    "        avg_response = cell_response[conv_mask].mean()\n",
    "        \n",
    "        ## END CODE HERE\n",
    "        \n",
    "        # store the average response in the storage array\n",
    "        avg_counts[b] = avg_response\n",
    "    \n",
    "    return avg_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324293d0-3ee0-4b65-8f36-efd56a63f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis = get_avg_spk_cts_per_bin(\n",
    "    convolved_signal,\n",
    "    training_spikes[:, num_past_pulses - 1:],\n",
    "    bin_edges\n",
    ")\n",
    "\n",
    "print(y_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9796600-579a-479a-96a6-b3f2c9c0bb08",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "[0.         0.         0.         0.02941176 0.02898551 0.00606061\n",
    " 0.01866667 0.02162162 0.01901975 0.01912682 0.01178838 0.01228105\n",
    " 0.0082722  0.00769027 0.0068076  0.01086694 0.02331304 0.07017818\n",
    " 0.1418298  0.27354766 0.44942832 0.53728223 0.69291339 0.71468144\n",
    " 0.7431694  0.64179104 0.96       1.125      2.                nan]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9ba3fd-1c99-485c-b010-3269c915a746",
   "metadata": {},
   "source": [
    "It's okay if this cell shows a big red warning. Do you know why it's throwing the warning, though? Why is there a `nan` in the array?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928852e7-8c20-4e59-bac5-ae0ba1b2bfd1",
   "metadata": {},
   "source": [
    "Now you have the **y-axis** to the plot you want! What should the corresponding **x-axis** be?\n",
    "\n",
    "Well, the bin centers! So go ahead calculate those."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c593a17f-b66d-4fd2-b741-7f8fc70e8ae5",
   "metadata": {},
   "source": [
    "**Exercise:** compute the x-axis using the bin edges, taking the mean of the upper and lower bin edges for each bin as the bin center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d15b7a0-270e-4537-8769-b26d15b3423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "x_axis = (bin_edges[1:] + bin_edges[:-1]) / 2\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc91ae5-21f6-4d9e-b4be-79a9e996d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcd5e99-a525-44d2-b40a-2c02e1b9dfa5",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "[-5.8 -5.4 -5.  -4.6 -4.2 -3.8 -3.4 -3.  -2.6 -2.2 -1.8 -1.4 -1.  -0.6\n",
    " -0.2  0.2  0.6  1.   1.4  1.8  2.2  2.6  3.   3.4  3.8  4.2  4.6  5.\n",
    "  5.4  5.8]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1463203-7e22-4faa-a402-90b14410f7e2",
   "metadata": {},
   "source": [
    "Alright, let's plot this relationship!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a11df-eff9-4c35-9234-4ede6a747273",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "ax.scatter(\n",
    "    convolved_signal.ravel(),\n",
    "    training_spikes[:, num_past_pulses - 1:].ravel(),\n",
    "    c=\"tab:green\",\n",
    "    s=2\n",
    ")\n",
    "ax.bar(\n",
    "    x_axis, \n",
    "    y_axis + 0.1,\n",
    "    width=0.36,  # change this if need be, to make plot more readable\n",
    "    color=(0.0, 0.0, 0.0, 0.0),\n",
    "    edgecolor=(0.9, 0.4, 0.2, 1.0),\n",
    "    bottom=-0.1\n",
    ")\n",
    "ax.set_xlabel(\"Values of the Convolved Signal\")\n",
    "ax.set_ylabel(\"Average Spike Count\")\n",
    "ax.set_title(\"Relationship between the convolved signal and spike counts\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e15dce0-095f-4690-a7a5-a14c16092c0d",
   "metadata": {},
   "source": [
    "This looks promising!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22124b98-7cab-4bb6-bd8d-06a409d3efe4",
   "metadata": {},
   "source": [
    "The histogram in red captures some of the non-linear nature of the cell's response, although not all of it. This histogram would also look different depending on how you bin the x-axis. Feel free to re-run the previous few cells with a different number of bins and see what the plot looks like (Make sure to change the `width` argument to `ax.bar` if you change the number of bins)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c2d82e-6dfd-42ea-8229-4b7d0a520841",
   "metadata": {},
   "source": [
    "Would it be reasonable to expect that binning and averaging alone will capture the cell's more extreme responses (i.e. largest spike counts)?\n",
    "\n",
    "Well, no. But this does not mean the model doesn't have any predictive power! In fact, let's first try and predict something with the model, and then see how you could improve this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7637e30b-cc60-4c50-bb04-718c36326bc9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65775c10-1681-4355-9811-31c65a7e9bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential(x, a, b, c):\n",
    "    return a * np.exp(b * x + c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343387c9-af2a-4e50-97d8-153f3ecbdc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softplus(x, a, b, c):\n",
    "    return a * np.log(1 + np.exp(b * x + c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c40c6a-ac07-4b0b-a068-58bd26bfd554",
   "metadata": {},
   "outputs": [],
   "source": [
    "function = exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90980483-da36-4f7f-8444-1cb308faedc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_params_data, _ = curve_fit(\n",
    "    f=function,\n",
    "    xdata=convolved_signal.ravel(),\n",
    "    ydata=training_spikes[:, num_past_pulses-1:].ravel(),\n",
    "    bounds=([0, -np.inf, -np.inf], np.inf),\n",
    "    p0=[0.50, 6.00, -4.0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a630cf-1dea-4701-9db5-6ff939fc88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis_copy = y_axis.copy()\n",
    "if np.any(np.isnan(y_axis_copy)):\n",
    "    for i, val in enumerate(y_axis_copy):\n",
    "        if np.isnan(val) and i == 0:\n",
    "            y_axis_copy[i] = 0\n",
    "        if np.isnan(val) and i > 0:\n",
    "            y_axis_copy[i] = y_axis_copy[i-1]\n",
    "\n",
    "optimal_params_histogram, _ = curve_fit(\n",
    "    f=function,\n",
    "    xdata=x_axis,\n",
    "    ydata=y_axis_copy,\n",
    "    bounds=([0, -np.inf, -np.inf], np.inf),\n",
    "    p0=[0.50, 6.00, -4.0],\n",
    "    maxfev=4000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170bdfd1-0c2c-464a-b1fc-1534606ab45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_params_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3156829-15ea-4d1d-8852-70c9b81cc394",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_params_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0424bb0-8eb7-40ec-8858-1a302c5cb5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fit_data = function(x_axis, *optimal_params_data)\n",
    "y_fit_hist = function(x_axis, *optimal_params_histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0917d91e-30c6-4085-a287-efa09f5578cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "ax.scatter(\n",
    "    convolved_signal.ravel(),\n",
    "    training_spikes[:, num_past_pulses-1:].ravel(),\n",
    "    c=\"tab:green\",\n",
    "    s=2\n",
    ")\n",
    "ax.bar(\n",
    "    x_axis, \n",
    "    y_axis + 0.1,\n",
    "    width=0.36,\n",
    "    color=(0.0, 0.0, 0.0, 0.0),\n",
    "    edgecolor=(0.9, 0.4, 0.2, 1.0),\n",
    "    bottom=-0.1\n",
    ")\n",
    "ax.plot(\n",
    "    x_axis,\n",
    "    y_fit_data,\n",
    "    c=\"tab:blue\",\n",
    "    lw=2,\n",
    "    label=\"data\",\n",
    ")\n",
    "ax.plot(\n",
    "    x_axis,\n",
    "    y_fit_hist,\n",
    "    c=\"tab:orange\",\n",
    "    lw=2,\n",
    "    label=\"histogram\"\n",
    ")\n",
    "ax.set_xlabel(\"Values of the Convolved Signal\")\n",
    "ax.set_ylabel(\"Average Spike Count\")\n",
    "ax.set_title(\"Relationship between the convolved signal and spike counts\")\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5db23-207b-49de-83f9-61e3a4303af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
