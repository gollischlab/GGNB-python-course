{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c23736-a749-43aa-8c68-d69cd1556039",
   "metadata": {},
   "source": [
    "# Project 2: The Linear-Nonlinear Model\n",
    "\n",
    "Over the last two and a half days, you've learned how to analyze spike trains recorded under visual stimulation and also how to calculate the spike-triggered average (STA). As a final project in this course, you will turn to a very common modelling tool used in sensory systems neuroscience, the linear-nonlinear (LN) model.\n",
    "\n",
    "The LN model provides a simple way to predict a neuron's response to novel stimuli. At its core, the model assumes that the more similar a stimulus is to the cell's STA, the more the cell will fire. The similarity measure is a **linear** mathematical operation called a *convolution*, and the relationship between the result of the convolution and the cell's spiking output is **non-linear**. This combination of **linear + non-linear** is the reason the LN model is called the way it is called.\n",
    "\n",
    "This brings the LN model down to three steps:\n",
    "\n",
    "- compute the cell's STA\n",
    "- compute the convolution between the receptive field and the stimulus\n",
    "- find / fit the non-linear relationship between the convolution output and the firing rate\n",
    "\n",
    "At the end of this project, you'll be able to use the LN model to predict the responses of retinal ganglion cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06c6da-36ba-4baa-905e-cdb8bd1970d5",
   "metadata": {},
   "source": [
    "Let's begin by importing the required packages and defining some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c03d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.rc={'figure.figsize': (12, 6), 'font.size': 14 }\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import pearsonr\n",
    "from numpy import load\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e34f8-3287-446c-ae6f-edd54b608551",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HELPER FUNCTIONS ###\n",
    "# Please run this cell #\n",
    "# before starting with #\n",
    "#     the notebook     #\n",
    "########################\n",
    "\n",
    "\n",
    "def plot_rasters(\n",
    "    response_matrix: np.ndarray,\n",
    "    ax: plt.Axes,\n",
    "    sampling_rate: float,\n",
    "    **kwargs\n",
    "):\n",
    "    for t, trial in enumerate(response_matrix):\n",
    "        spike_list = []\n",
    "        for c, spike_count in enumerate(trial):\n",
    "            if spike_count > 0:\n",
    "                spike_list.extend((np.random.random(size=spike_count) + c).tolist())\n",
    "\n",
    "        if spike_list:\n",
    "            ax.plot(\n",
    "                np.array(spike_list) / sampling_rate,\n",
    "                [1 + t] * len(spike_list),\n",
    "                **kwargs\n",
    "            )\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fe1d83-e5c8-49a8-b43e-5fb78b7ade1a",
   "metadata": {},
   "source": [
    "Earlier today, you learned how to compute the STA for a cell given the cell's response to a certain stimulus. This means **you've already implemented the first step of the LN model!** This also means we'll be able to re-use some of the functions we wrote earlier. These have been carried over and defined for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e85399-403a-49b5-ad81-675b8cfeb60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sta(\n",
    "    spike_times_array,\n",
    "    stimulus_array,\n",
    "    pulses_array, \n",
    "    training_frames,\n",
    "    test_frames,\n",
    "    past_frames,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute a cell's spike-triggered average (STA) given it's responses to a visual stimulus.\n",
    "    \"\"\"\n",
    "    # reshape the stimulus and pulses using the training_frames and test_frames\n",
    "    stimulus_reshaped, pulses_reshaped = get_reshaped_stimulus_and_pulses(\n",
    "        stimulus_array,\n",
    "        pulses_array,\n",
    "        training_frames,\n",
    "        test_frames\n",
    "    )\n",
    "    \n",
    "    # select only those spikes which occur during the stimulus presentation\n",
    "    spikes_in_stimulus = spike_times_array[  # select...\n",
    "        (spike_times_array > pulses_reshaped.ravel()[0]) &  # ... all spikes after the first pulse\n",
    "        (spike_times_array < pulses_reshaped.ravel()[-1])  # ... and all spikes before the last pulse\n",
    "    ]\n",
    "    \n",
    "    # bin the spike train using the reshaped pulses\n",
    "    spikes_binned = compute_binned_spikes(\n",
    "        spikes_in_stimulus,\n",
    "        pulses_reshaped\n",
    "    )\n",
    "    \n",
    "    # reshape the binned spikes to the same shape as reshaped_pulses\n",
    "    spikes_in_trials = np.reshape(spikes_binned, reshaped_pulses.shape)\n",
    "    \n",
    "    # split spikes into training and test\n",
    "    training_spikes, _ = split_into_two(\n",
    "        spikes_in_trials,\n",
    "        training_frames\n",
    "    )\n",
    "    \n",
    "    # split stimulus into training and test\n",
    "    training_stimulus, _ = split_into_two(\n",
    "        stimulus_reshaped,\n",
    "        training_frames\n",
    "    )\n",
    "    \n",
    "    # get stimulus snippets past_frames before each spike\n",
    "    stimulus_snippets = get_stimulus_stack(\n",
    "        training_spikes,\n",
    "        training_stimulus,\n",
    "        past_frames\n",
    "    )\n",
    "    \n",
    "    # average over the stimulus snippets\n",
    "    sta = stimulus_snippets.mean(axis=0)\n",
    "    \n",
    "    return sta\n",
    "\n",
    "\n",
    "def get_stimulus_stack(training_spikes_array, training_stimulus, past_frames):\n",
    "    \"\"\"\n",
    "    Extract stimulus values before each spike in the training set, ignoring\n",
    "    the first past_frames bins.\n",
    "    \"\"\"\n",
    "    snippets = []  # create an empty list\n",
    "    \n",
    "    for t, trial in enumerate(training_spikes_array):  # loop over trials\n",
    "        for b, bin_count in enumerate(trial):  # loop over bins in trial\n",
    "            # only for bins after first past_frames frames\n",
    "            if (b + 1 >= past_frames) \\\n",
    "               and (bin_count > 0):  # and only for bins which have at least 1 spike\n",
    "                snippet = training_stimulus[\n",
    "                    t, b + 1 - past_frames:b + 1\n",
    "                ]  # cut out past_frames frames before the spike from the stimulus\n",
    "                for i in range(bin_count):  # append once to list for every spike in bin\n",
    "                    snippets.append(snippet)\n",
    "    \n",
    "    return np.array(snippets)  # return a numpy array\n",
    "\n",
    "\n",
    "def compute_binned_spikes(spike_times_array, reshaped_pulses_array):\n",
    "    \"\"\"\n",
    "    Bin spikes according to the bin edges defined by the pulses.\n",
    "    \"\"\"\n",
    "    binned_spike_array = np.bincount(\n",
    "        np.digitize(\n",
    "            x=spike_times_array,\n",
    "            bins=reshaped_pulses_array.ravel(),\n",
    "        ) - 1,  # important to make sure the bin ids of the spikes align with the stimulus\n",
    "        minlength=reshaped_pulses.size\n",
    "    )\n",
    "    \n",
    "    return binned_spike_array\n",
    "\n",
    "\n",
    "def split_into_two(two_dimensional_array, split_id):\n",
    "    \"\"\"\n",
    "    Split the input 2d-array along its second dimension into two sets at split_id.\n",
    "    \"\"\"\n",
    "    first_array = two_dimensional_array[:, :split_id]\n",
    "    second_array = two_dimensional_array[:, split_id:]\n",
    "    \n",
    "    return first_array, second_array\n",
    "\n",
    "\n",
    "def get_reshaped_stimulus_and_pulses(stimulus_array, pulses_array, training_frames, test_frames):\n",
    "    \"\"\"\n",
    "    Return the stimulus and pulses arrays reshaped to (trials x frames).\n",
    "    \"\"\"    \n",
    "    # compute the total number of trials in the experiment\n",
    "    frames_per_trial = training_frames + test_frames\n",
    "    total_trials = int(np.floor(pulses_array.size / frames_per_trial))\n",
    "    \n",
    "    # truncate stimulus and pulses to match the total number of complete trials\n",
    "    pulses_array = pulses_array[:total_trials * frames_per_trial]\n",
    "    stimulus_array = stimulus_array[:total_trials * frames_per_trial]\n",
    "    \n",
    "    # reshape stimulus and pulses\n",
    "    pulses_reshaped = np.reshape(pulses_array, (total_trials, frames_per_trial))\n",
    "    stimulus_reshaped = np.reshape(stimulus_array, (total_trials, frames_per_trial))\n",
    "    \n",
    "    return stimulus_reshaped, pulses_reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a64417-e080-4628-9f90-1024ae7dbfb9",
   "metadata": {},
   "source": [
    "# 1 - The stimulus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d86894-1467-4b9e-b16d-854c2b0c1c60",
   "metadata": {},
   "source": [
    "For this project, you will work with the same stimulus that you worked with this morning. As a quick recap, the full-field flicker consists of a screen-wide presentation of contrast levels that change with a given frequency (here 75Hz). The contrast value of each presentation is calculated from a number that's been drawn from a Gaussian distribution of mean zero and standard deviation 0.3, with positive values representing brighter presentations, and vice-versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a862099-798d-4210-b5d0-81c446a68daa",
   "metadata": {},
   "source": [
    "This is what it looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa270b95-9de6-46dc-bba5-c525aeb2f869",
   "metadata": {},
   "source": [
    "<center><img src=\"images/fff.gif\" width=\"200\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762ec2a9-2a8b-48cb-a176-d10470cc0160",
   "metadata": {},
   "source": [
    "The stimulus is composed of a **training set** and a **test set**, each containing a sequence of contrast values. The values in the training set are completely random and **do not repeat**, whereas those in the test set **repeat across across trials**. The test set is repeated in every trial to account for any variability, for eg. from experimental noise, that may arise in the cell's responses. \n",
    "\n",
    "The model will be evaluated on the average response of the cell to the test stimulus across trials. This also means you'll be making use of the test set in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe15e562-4061-48f4-adc1-fd2558cbbb6d",
   "metadata": {},
   "source": [
    "<p><center><img src=\"images/FFFstimstructure.png\" width=\"600\" height=\"400\"></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d5b9b-391e-4be9-a339-337f10e93aa0",
   "metadata": {},
   "source": [
    "# 2 - Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a25854-4fc4-49df-9db4-ac544782de2f",
   "metadata": {},
   "source": [
    "To begin with, let us load the stimulus and pulses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a865d-ab91-4eb1-9a4d-be8a2ab1187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulses_filepath = 'data_LN_model/frametimes_fullfieldnoise.txt'\n",
    "pulses = np.loadtxt(pulses_filepath)\n",
    "\n",
    "## Each pulse marks a change in stimulus presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc17f0e-6729-4e46-8f67-1a4aaf40d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_filepath = 'data_LN_model/stimulus_fullfieldnoise.txt'\n",
    "stimulus = np.loadtxt(stimulus_filepath)\n",
    "\n",
    "## Each value is a contrast value of the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b082ba1a-fcce-45a2-9e61-2ccb1a252798",
   "metadata": {},
   "source": [
    "You will again start by working with a single cell. So load up the spike times for one cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d29157-8ca7-4cfc-884f-117daf732c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_filepath = 'data_LN_model/fullfieldnoise_C6.txt'\n",
    "spike_times = np.loadtxt(st_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd53b87-9bda-43ef-bda1-0ac8cc8f6fe7",
   "metadata": {},
   "source": [
    "Next, let us define some of the important variables we used earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9513e512-ab80-432c-b335-f7b1189f836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nframes_training = 1800\n",
    "nframes_test = 600\n",
    "num_past_pulses = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5921dc68-eec4-418e-a393-e4bf04a8f027",
   "metadata": {},
   "source": [
    "**Recap:** use the functions we carried over to reshape the stimulus and pulses arrays into the shape `(trials x frames)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f775120e-a2d7-4479-b1e1-daa73d1bf750",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc5fe0-506b-48aa-bfbb-1d357d5fc408",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "reshaped_stimulus, reshaped_pulses = get_reshaped_stimulus_and_pulses(\n",
    "    stimulus,\n",
    "    pulses,\n",
    "    nframes_training,\n",
    "    nframes_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63cc311-a009-44d2-a5e0-4b05ca49a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshaped_stimulus.shape)\n",
    "print(reshaped_pulses.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df492f33-6af4-4279-9934-b81d5aa3fbdc",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "(41, 2400)\n",
    "(41, 2400)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b603a262-a92a-40b2-9a23-f7a5debceadc",
   "metadata": {},
   "source": [
    "**Recap:** prepare the spike trains, by selecting spikes only those spikes relevant for the stimulus, binning them and reshaping them into trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d33ebb0-1edf-4bb8-92c3-2969b40b3042",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "stimulus_spiketimes = spike_times[  # select...\n",
    "      # ... all spikes after the first pulse\n",
    "      # ... and all spikes before the last pulse\n",
    "]\n",
    "\n",
    "binned_spikes = \n",
    "\n",
    "spikes_in_trials = \n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f0a7db-64bb-4617-8634-8e008ca99b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "stimulus_spiketimes = spike_times[  # select...\n",
    "    (spike_times > reshaped_pulses.ravel()[0]) &  # ... all spikes after the first pulse\n",
    "    (spike_times < reshaped_pulses.ravel()[-1])  # ... and all spikes before the last pulse\n",
    "]\n",
    "\n",
    "binned_spikes = compute_binned_spikes(stimulus_spiketimes, reshaped_pulses)\n",
    "\n",
    "spikes_in_trials = binned_spikes.reshape(reshaped_pulses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbf3af6-686a-472f-93aa-a7ceda4c0316",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_in_trials.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f1514-7062-4393-868d-9c91ad41c81c",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "(41, 2400)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2658e1-4ec3-4106-85cc-a79575a72222",
   "metadata": {},
   "source": [
    "Lastly, you need to divide the binned spike trains into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b946c73-7668-4a6a-95dc-676260324215",
   "metadata": {},
   "source": [
    "**Exercise:** split the binned spike trains into training and test sets\n",
    "\n",
    "*Hint:* you can use functions we've already defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd7afc2-579e-4d3f-8779-4a3c7544ad5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a4645b-25fa-476d-afca-2698740254ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "training_spikes, test_spikes = split_into_two(spikes_in_trials, nframes_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5523a2ab-4631-4379-ae99-990aa1a643ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(training_spikes.shape)\n",
    "print(test_spikes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40402183-2943-40cb-91a2-f7a0c03edd74",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "(41, 1800)\n",
    "(41, 600)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386e0b7-8258-40c5-80f8-ebccf9838547",
   "metadata": {},
   "source": [
    "Before diving head long into the modelling itself, it might be worth looking at what exactly we want to be able to model / predict in the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c7677f-adf7-4a3c-9b96-c0fccda03607",
   "metadata": {},
   "source": [
    "### Visualizing the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7a0c2d-99f0-4be8-8c7c-ad0ceb6ed470",
   "metadata": {},
   "source": [
    "Each trial in the stimulus has a training and a test set. Throughout the previous session on STAs, you focused on the training set, but what you actually want to predict are the cell's responses to the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959548-b669-441c-ba69-eae0dce6cc01",
   "metadata": {},
   "source": [
    "More specifically, you want to be able to predict the **cell's average response to the test set**. So, let's calculate that quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327c9174-6887-485b-a160-e70410f021cf",
   "metadata": {},
   "source": [
    "**Exercise:** compute the average response of the cell to the test set and call it `ground_truth`\n",
    "\n",
    "*Hint:* the average here is across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1417e1bc-f695-4f64-8b69-64d6c7acd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e849e25-9351-4913-a166-86268b51a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "ground_truth = test_spikes.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cac969-d13d-4b07-ab61-9426ca1097d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ground_truth[:10])  # first ten bins\n",
    "print(ground_truth[-10:])  # last ten bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74616ea-4e52-4b6e-8363-f5147006119f",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "[0.         0.19512195 0.19512195 0.07317073 0.09756098 0.04878049\n",
    " 0.09756098 0.12195122 0.         0.04878049]\n",
    "[0.56097561 0.43902439 0.19512195 0.17073171 0.         0.04878049\n",
    " 0.04878049 0.12195122 0.02439024 0.04878049]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b15ee7-dd1f-494c-abc4-c71b2ff1bfef",
   "metadata": {},
   "source": [
    "Let's also plot this, along with the spike rasters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1f8b32-6bb7-41c5-a132-92d2cf566d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(15, 6), layout=\"constrained\", sharex=True, sharey=False, height_ratios=[3, 7])\n",
    "\n",
    "axs[0].plot(ground_truth, lw=2)\n",
    "axs[0].set_ylabel(\"spike count per bin\")\n",
    "\n",
    "axs[1] = plot_rasters(\n",
    "    response_matrix=test_spikes,\n",
    "    ax=axs[1],\n",
    "    sampling_rate=1.,\n",
    "    c='k',\n",
    "    marker=\".\",\n",
    "    markersize=1.,\n",
    "    lw=0,\n",
    ")\n",
    "axs[1].set_xlabel(\"time bins\")\n",
    "axs[1].set_ylabel(\"trials\")\n",
    "\n",
    "plt.suptitle(\"average test response for one cell\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ace89ba-eae3-4111-ae99-3175601a534b",
   "metadata": {},
   "source": [
    "This is the response of this cell to the test stimulus over 41 trials. Take a minute to examine this figure.\n",
    "\n",
    "The top plot shows the average number of spikes in each bin across all trials. The bottom plot is a raster plot of the kind you saw in the previous session, with each dot representing a spike and the rows representing trials. So, the blue trace is a result of averaging the spikes in the bottom plot across trials.\n",
    "\n",
    "Each sharp increase in the spike count in the top plot probably came right after a stimulus that the cell seemed to like! There were also periods of almost no activity (where the average spike count was zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edae08c-ca82-47e6-9051-502b24e945f5",
   "metadata": {},
   "source": [
    "At the end of this notebook, your model should be able to follow the trace in the top plot at least partially, if not completely.\n",
    "\n",
    "Let's see if this is the case!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff698c49-3bb1-47ba-890c-90ba0298a281",
   "metadata": {},
   "source": [
    "# 3 - Compute the STA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04073fd-15a6-4891-9d51-6ef74afcf8f4",
   "metadata": {},
   "source": [
    "This should be quick!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a878c8f-7431-40db-ab65-300e86f2d20e",
   "metadata": {},
   "source": [
    "**Exercise:** using the functions and variables defined earlier, calculate the STA for the cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54c4d08-8a21-4f1f-b4e8-a520ef9e2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb93284a-de3b-4486-89d1-d72a7cd0cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "sta = calculate_sta(\n",
    "    spike_times,\n",
    "    stimulus,\n",
    "    pulses,\n",
    "    nframes_training,\n",
    "    nframes_test,\n",
    "    num_past_pulses,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86df9ab-3dca-401a-9c92-960a574a572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c29ba5-e6c0-485f-9a32-2e31afd4a25d",
   "metadata": {},
   "source": [
    "**Expected output:** \n",
    "\n",
    "```\n",
    "(45,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbc7a40-b04b-4f22-983a-4a8b220fc771",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(sta[::-1], lw=2)\n",
    "ax.set_xlabel(\"time before spike (bins)\")\n",
    "ax.set_ylabel(\"contrast values\")\n",
    "ax.set_title(\"a new sta this time!\")\n",
    "ax.invert_xaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dd01b9-8f94-4a73-8dcb-51c20758bcb8",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "Before moving on, you will need to normalize the STA. This would ensure that the amplitude of the STA does not vary widely from cell to cell, which ensures more reliable model fitting. There are various ways in which a given signal can be normalized (the [wikipedia page](https://en.wikipedia.org/wiki/Normalization_(statistics)) is a good resource to start from). In this case, you want to have a predictable range of values for your STA irrespective of what cell you're analyzing.\n",
    "\n",
    "To this end, you must **divide** the STA by its standard deviation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388b68d9-237f-417f-8e07-80e7bdaa4c91",
   "metadata": {},
   "source": [
    "**Exercise:** divide the STA by it's standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693ec0c0-944b-45ac-8770-c00f38b8d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4191f3-863d-4702-8645-7504bafae8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "sta /= sta.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124117f1-ad87-4ae0-b1ef-a4f4ebe365af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sta.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa1d7f7-ca30-4cb0-9eeb-32d23227659a",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d23b7f9-ba20-478b-bfbe-1876a1ecd98d",
   "metadata": {},
   "source": [
    "The normalization ensures that the standard deviation of the STA is 1.0! Since we know that the standard deviation of the stimulus is always 0.3, we can be certain that when we convolve the two signal, the standard deviation of the convolution output will always have values in the same range irrespective of what cell we analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf9b9b1-aed4-4fd9-afa0-502a7bc2219e",
   "metadata": {},
   "source": [
    "We are now ready to tackle convolutions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6cde6f-1875-40a0-a45d-1543fb574ecf",
   "metadata": {},
   "source": [
    "# 4 - Convolve the stimulus with the STA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c290e4a8-8c45-4ac3-a5f0-de9428be29a3",
   "metadata": {},
   "source": [
    "### What are convolutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53cdd82-2744-415d-a710-20cf70b6e7aa",
   "metadata": {},
   "source": [
    "Convolution is a mathematical operation that combines two functions to produce a third function. In the context of time-series analysis, convolution allows us to express the relationship between two signals in terms of their overlap.\n",
    "\n",
    "Given two time-series signals, let's call them **signal** and **kernel**, the convolution of these signals is calculated by sliding the kernel across the signal and multiplying the corresponding values at each position, then summing up the results. This sliding operation effectively measures the similarity between the signals at different time points.\n",
    "\n",
    "Convolution is widely used in various fields, including signal processing, image processing, and machine learning. It can be utilized for tasks such as filtering, feature extraction, and pattern recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e71f1-9c4d-488e-ad9b-113c14b880bd",
   "metadata": {},
   "source": [
    "### Example: convolution of two signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5521b941-97a9-4470-9d7e-cc343288aa8f",
   "metadata": {},
   "source": [
    "Consider the following graphic:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7130781d-c771-4064-aaec-f3e1c62e4413",
   "metadata": {},
   "source": [
    "<center><img src=\"../images/convolution.gif\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad429f4-2faf-4b73-838d-d37719bc793f",
   "metadata": {},
   "source": [
    "The red curve in the top plot is the **signal** and the green curve sliding across the plot is the **kernel**. The bottom plot shows the result of convolution as the kernel slides over the signal. Each point in the bottom plot is the result of the sum of the element-wise multiplication of the kernel with the signal it overlaps with. As a result, the peak of the triangle corresponds to the point where both the kernel and the signal completely overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2926672a-bac2-4309-8773-3c873a8fd815",
   "metadata": {},
   "source": [
    "### Convolving the stimulus with the STA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2792b54-151d-4bd0-a30c-4751a6e65c1f",
   "metadata": {},
   "source": [
    "In our case, the **signal** is the stimulus and the **kernel** is the STA. The result of their convolution will yield a third signal in which higher values indicate stimuli that resembled the STA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4ef5d6-0538-487c-9833-6faf5f5da67a",
   "metadata": {},
   "source": [
    "Since you want to use the training set in the stimulus to train the model, and the test set only to evaluate the model performance, you must first split the `reshaped_stimulus` into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4571e8e-a119-45e3-994f-863123b9ea74",
   "metadata": {},
   "source": [
    "**Exercise:** split the `reshaped_stimulus` into training and test sets, just like you did for the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271b523-a4b9-415b-9d3f-3f5df0731a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e97cf0-38ba-46ef-9178-bc43fbc0ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "training_stimulus, test_stimulus = split_into_two(reshaped_stimulus, nframes_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e933c05-7aed-4638-89d8-d9f44cfb4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_stimulus.shape)\n",
    "print(test_stimulus.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7cc33-0dce-4f36-9012-604050d613e0",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "(41, 1800)\n",
    "(41, 600)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0aaecc-8cfa-4d6e-8603-462fd601fc2f",
   "metadata": {},
   "source": [
    "Now, to the convolution itself!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cdd889-197b-4980-8e1d-1e954bbd6762",
   "metadata": {},
   "source": [
    "**CAUTION:** the convention is that the STA must have it's elements ordered **backwards from the time of the spike**. So, you must remember to **flip the kernel (STA) before feeding it to the numpy `convolve` function**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee71e31e-0a6c-4865-b1dd-4c583981f85a",
   "metadata": {},
   "source": [
    "**Exercise:** complete the function that convolves the stimulus with the STA\n",
    "\n",
    "*Hint 1:* each trial should be convolved separately (why?), so make sure you loop over the trials\n",
    "\n",
    "*Hint 2:* use `np.convolve` to do the convolution using the mode \"valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1689d38-de71-4d4f-aa63-2933927103b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_stimulus_with_sta(stimulus_array, cell_sta):\n",
    "    \"\"\"\n",
    "    Use np.convolve to compute the trial-by-trial convolution\n",
    "    of the visual stimulus with a cell's spike-triggered avg.\n",
    "    \"\"\"\n",
    "    conv_list = []\n",
    "    \n",
    "    ## START CODE HERE ##\n",
    "    \n",
    "    \n",
    "        \n",
    "    ## END CODE HERE ##\n",
    "    \n",
    "    return np.array(conv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c025e072-265b-43a8-a9c5-3ab01bb24cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_stimulus_with_sta(stimulus_array, cell_sta):\n",
    "    \"\"\"\n",
    "    Use np.convolve to compute the trial-by-trial convolution\n",
    "    of the visual stimulus with a cell's spike-triggered avg.\n",
    "    \"\"\"\n",
    "    conv_list = []\n",
    "    \n",
    "    ## START CODE HERE ##\n",
    "    \n",
    "    for trial in stimulus_array:\n",
    "        conv = np.convolve(trial, cell_sta[::-1], mode=\"valid\")\n",
    "        conv_list.append(conv)\n",
    "        \n",
    "    ## END CODE HERE ##\n",
    "    \n",
    "    return np.array(conv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74322582-d44f-408c-9eeb-127381652385",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved_signal = convolve_stimulus_with_sta(training_stimulus, sta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a62af51-dbf7-4a9e-ba07-e7f0c99796e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(convolved_signal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38bbc60-f846-4f70-b1d6-dfa00b36ca72",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "(41, 1756)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e06101-ffa9-4278-a3d2-365e0220da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(convolved_signal[0, :10]) # first ten bins\n",
    "print(convolved_signal[-1, -10:]) # last ten bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe25cd-b75e-4dc0-a1fa-27eb17de0140",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "[ 0.09504644  0.29837892  1.8295958   6.2266448  10.72876016 15.24241819\n",
    " 16.13379787 12.77382108  3.21070508 -6.08765853]\n",
    "[ 7.99098308 11.35632167  8.99469585  6.02971824  2.90366299  3.886229\n",
    "  4.0111409   5.11022628  2.89511875  1.94620747]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b13646-10de-4de6-bc8d-ae99932db123",
   "metadata": {},
   "source": [
    "Now, feel free to plot and explore what the convolved stimulus looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59c4a96-6cc6-4a06-8d40-75e960662b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6), layout=\"constrained\")\n",
    "ax.plot(convolved_signal[0], lw=3)\n",
    "ax.set_xlabel(\"time bins\")\n",
    "ax.set_title(\"Convolved signal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec71f033-a613-4ee7-b023-fa461c32dc95",
   "metadata": {},
   "source": [
    "**Questions:** \n",
    "\n",
    "* why does the convolved signal have fewer time bins than the stimulus?\n",
    "* is there a way to compute number of time bins in the convolved signal given a stimulus and an STA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e6cd54-69ae-4c1b-a750-e52257db6dda",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5 - Relate the convolution to spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73922419-cb28-4af2-98c2-91521c3d85bb",
   "metadata": {},
   "source": [
    "Congratulations, you have the next piece of the LN puzzle: the convolved signal!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3915a9-c331-427d-b0d0-8ba4a5b5a3a5",
   "metadata": {},
   "source": [
    "You now need to figure out the relationship between the output of the convolution and the firing response of the cell. According to our assumptions, whenever the output of the convolution is large, the firing response of the cell is also large. How would you go about verifying this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe89569-6f8a-430b-a6fc-35f8f9add04a",
   "metadata": {},
   "source": [
    "Well, you want to find out how some change in the value of the convolved signal is translated to a change in the firing response of the cell. Since both the convolved signal and the spike train are binned in the same way, you could simply plot one against the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1c43bc-4505-411f-9d9d-c2fde34bf37f",
   "metadata": {},
   "source": [
    "**But do the `convolved_signal` and `training_spikes` have the same dimensions?**\n",
    "\n",
    "No! Although they have the same number of trials, they have different numbers of time bins. More specifically, **the first `num_past_pulses - 1` bins of `convolved_signal` are truncated**. This is a result of the convolution operation. We don't have time to go into the math here, but you're encouraged to read up about it, for eg [here](https://towardsdatascience.com/convolutions-in-one-dimension-using-python-54d743f18063)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d7fe50-7375-47d6-930f-2d93e955cc05",
   "metadata": {},
   "source": [
    "Okay, now try to plot the relationship between the `convolved_signal` and the `training_spikes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e870e336-02f0-4b07-a585-bec515b3fdd0",
   "metadata": {},
   "source": [
    "**Exercise:** complete the code below to plot values of the convolved signal on the x-axis and the corresponding spike counts from the training set on the y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95864464-4cef-46a9-a8dd-82397b1fd0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "\n",
    "## COMPLETE THE FOLLOWING LINE ##\n",
    "\n",
    "ax.scatter(      ,        , c=\"tab:green\", s=2)\n",
    "\n",
    "ax.set_xlabel(\"Values in the Convolved Signal\")\n",
    "ax.set_ylabel(\"Spike Count\")\n",
    "ax.set_title(\"Relationship between the convolved signal and spike counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615aa72-d652-4eb2-869e-130804c1a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "\n",
    "ax.scatter(convolved_signal.ravel(), training_spikes[:, num_past_pulses-1:].ravel(), c=\"tab:green\", s=2)\n",
    "\n",
    "ax.set_xlabel(\"Values in the Convolved Signal\")\n",
    "ax.set_ylabel(\"Spike Count\")\n",
    "ax.set_title(\"Relationship between the convolved signal and spike counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42563e81-920a-4940-91a0-ea532f2ed62f",
   "metadata": {},
   "source": [
    "This... is not very helpful, is it? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ec63d-6bbe-4ff7-94d0-fa7aaff9a37c",
   "metadata": {},
   "source": [
    "When the values of the convolved signal are small, the output spike count is also small, and vice-versa. The problem here is that the **spike counts are whole numbers** (0, 1, 2, 3...), so even for a large variation in the convolution output, the spike count only jumps between neighbouring values. Moreover, the cell is not entirely reliable - for the same value of a convolved signal, it could potentially have very different firing responses. What you would ideally like to have is a **smoother transition over the range of spike counts for any change in the convolution output**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbecc660-904e-4166-a2c6-3a622f19e1ba",
   "metadata": {},
   "source": [
    "### How do you fix this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4547750-8e80-4b89-9756-b2642d4ad5fc",
   "metadata": {},
   "source": [
    "**By fitting a curve!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2718e2-5be5-4ab4-ab51-a2de24929481",
   "metadata": {},
   "source": [
    "(Well, there is a lot more nuance to it than this, but for the illustrative and educative purposes of this course, fitting a nice curve to this plot should suffice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9535a0-8218-460e-a69e-e4fad46ed6dc",
   "metadata": {},
   "source": [
    "# 6 - Fit a Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d91a3eb-ba1e-4dd0-a61d-04719baca912",
   "metadata": {},
   "source": [
    "To fit a curve, you first need to decide what sort of a curve you'd like to fit. There are more than a few families of curves to choose from (and if you're more mathematically inclined, you could even come up with your own little curve that could work here). However, to keep things simple, you'll start with a simple **parametrized exponential**, the formula for which would be:\n",
    "\n",
    "$$\n",
    "f(x) = a \\cdot \\exp(b \\cdot x + c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a189bf3-b007-4018-9134-640ff31163d1",
   "metadata": {},
   "source": [
    "This is in effect just an exponential, the additional parameters allow us to fit it to our data a bit better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60128b9f-da6b-486f-906a-7122d5d4eebc",
   "metadata": {},
   "source": [
    "Go ahead and define this in a function!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97e2c2c-76b3-4f80-b05c-ac9c1a4dc051",
   "metadata": {},
   "source": [
    "**Exercise:** define a parametrized exponential function, with the first input argument as `x` and the subsequent ones being `a`, `b` and `c`. **The order of arguments is important here**. Internally, make use of the fact that the input `x` will always be a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e17dab-e472-46ed-a53c-3741dab394be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "def exponential(   ):\n",
    "    \n",
    "    return \n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9790ca-49f8-4485-910a-08c008acfdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "def exponential(x, a, b, c):\n",
    "    \"\"\"\n",
    "    A parametrized exponential.\n",
    "    \"\"\"\n",
    "    return a * np.exp(b * x + c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d305b4-78b8-4ee0-9c88-c77a5ddba083",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exponential(np.arange(10), 0.5, 0.5, -0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84bdb7-bfa4-49ae-a4c7-6b60cf12e26c",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "[ 0.30326533  0.5         0.82436064  1.35914091  2.24084454  3.69452805\n",
    "  6.09124698 10.04276846 16.55772598 27.29907502]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c5a4f-8962-4d35-bd7c-665df061947a",
   "metadata": {},
   "source": [
    "Fantastic! Now you have a function you can fit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6532dd-1a61-4fe6-8f10-5db146855aae",
   "metadata": {},
   "source": [
    "For the fitting itself, we'll be using the function `curve_fit` provided by the `optimize` module of the package `scipy`. This has already been imported in the notebook, but you're encouraged to go through the documentation for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7c5377-b114-4cbc-995a-fafa2edc01df",
   "metadata": {},
   "source": [
    "### Curve fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d558411-cb2a-43b2-9a72-a92154413aec",
   "metadata": {},
   "source": [
    "`curve_fit` takes as input:\n",
    "\n",
    "1. the function you want to fit, \n",
    "2. the x axis values and the y axis values from our data, \n",
    "3. bounds we'd like to enforce on our parameters, and\n",
    "4. an initial set of parameters\n",
    "\n",
    "and returns the set of optimal parameters (in the order of their input into the function)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1702cc0-36df-472f-9df4-fbba40976fc1",
   "metadata": {},
   "source": [
    "In the parametrized exponential function, we can be relatively certain that the output of the function needs to be positive. This sets a lower bound on `a` at `0`. However, none of the other parameters have an obvious bound to them, so it's best to provide no other bound to the fitting algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab386522-6889-48f7-9443-5b092b902cb8",
   "metadata": {},
   "source": [
    "Choosing the right set of initial parameters is an art unto itself, and is probably worth spending more time on than we have in this course. For now, a reasonable set of initial parameters have been chosen for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2791f2ca-d7cf-45c2-94ae-be0bbf199733",
   "metadata": {},
   "source": [
    "**Exercise:** fill out the missing arguments to the `curve_fit` function\n",
    "\n",
    "*Hint 1:* the function argument should be without parantheses\n",
    "\n",
    "*Hint 2:* remember to .`ravel()` the x- and y-axis values\n",
    "\n",
    "*Hint 3:* make sure the x- and y-axis values have the same shape (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9a629-0bcb-4d46-a1df-5d314ab042fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILL IN THE MISSING ARGUMENTS ##\n",
    "\n",
    "optimal_parameters, _ = curve_fit(\n",
    "    f=,  # the function you'd like to fit\n",
    "    xdata=  # x axis values\n",
    "    ydata=  # y axis values\n",
    "    p0=[2.0, 0.5, -1.5],  # initial parameters\n",
    "    bounds=([0, -np.inf, -np.inf], np.inf),  # bounds\n",
    "    maxfev=4000,  # just making sure the algorithm converges, hehe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d706233-9581-4c5c-9ff6-08cd0fec6a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "optimal_parameters, _ = curve_fit(\n",
    "    f=exponential,  # the function we'd like to fit\n",
    "    xdata=convolved_signal.ravel(),  # x axis values\n",
    "    ydata=training_spikes[:, num_past_pulses - 1:].ravel(),  # y axis values\n",
    "    p0=[2.0, 0.5, -3.0],  # initial parameters\n",
    "    bounds=([0, -np.inf, -np.inf], np.inf),  # bounds\n",
    "    maxfev=4000,  # just making sure the algorithm converges, hehe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00445c-880e-458d-859c-5a9f762aa212",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede33ed4-6e06-4101-b8f1-d6b441d7ef39",
   "metadata": {},
   "source": [
    "The exact fit parameters will be different for everyone, so there is only one way to check if the fit makes any sense: by plotting it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e4aa06-685c-452a-88e0-e13acb65b07c",
   "metadata": {},
   "source": [
    "What you want to plot is the output of the exponential function for a set of x-axis values, given the optimal parameters. In the next cell, a set of `x_values` is defined spanning the range of values you see in the data. \n",
    "\n",
    "\n",
    "What you must do is compute the exponential for those `x_values` using the optimal parameters you just calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf154a0-7fcf-43db-99a0-c502e36e7919",
   "metadata": {},
   "source": [
    "**Exercise:** complete the code to compute `y_fit`, feeding `x_values` and `optimal_parameters` as input to the exponential function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6073804-b54c-4337-af7d-d1f119a9971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = np.linspace(\n",
    "    start=np.floor(convolved_signal.min()),\n",
    "    stop=np.ceil(convolved_signal.max()),\n",
    "    num=51\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a63200-248b-439b-9e8f-227b5efcf948",
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPLETE THE FOLLOWING LINE ##\n",
    "\n",
    "y_fit = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e637ad9-e6a7-4f61-b93f-0d4a178b1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "y_fit = exponential(x_values, *optimal_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505ccf50-b0d1-46c9-809b-c1cac8d5a497",
   "metadata": {},
   "source": [
    "Time to see the plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e13e73-c0ad-4167-8469-54d34d441029",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "ax.scatter(convolved_signal.ravel(), training_spikes[:, num_past_pulses-1:].ravel(), c=\"tab:green\", s=2)\n",
    "ax.plot(x_values, y_fit, lw=3, c=\"tab:orange\", label=\"exp. fit\")\n",
    "ax.set_xlabel(\"Values in the Convolved Signal\")\n",
    "ax.set_ylabel(\"Spike Count\")\n",
    "ax.set_title(\"Relationship between the convolved signal and spike counts\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee538ae0-6642-4bac-9c0b-75b7a297da71",
   "metadata": {},
   "source": [
    "Excellent!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff82bbbb-e19c-4599-820a-1f21d095dda7",
   "metadata": {},
   "source": [
    "You now have a smooth function that translates changes in the convolution output to changes in spiking activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b07dc67-e2ac-4070-a141-5971c7e0f481",
   "metadata": {},
   "source": [
    "It's time to predict!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9565c84-29b1-40dd-8491-6d18e2d54c47",
   "metadata": {},
   "source": [
    "# 7 - Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3946b885-ebbe-4bee-bd43-182b37cfc314",
   "metadata": {},
   "source": [
    "Prediction is the quickest part of the model. What you need to do is as follows:\n",
    "\n",
    "1. convolve the test stimulus with the STA to get a `test_convolved` signal\n",
    "2. pass the values of the `test_convolved` signal to the exponential function, along with the optimal parameters you computed, to get predicted responses\n",
    "3. compare and plot the cell's ground truth response with the predicted response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc71017-6a4a-41f5-96da-4e351764a206",
   "metadata": {},
   "source": [
    "So let's get to it - let's see if you can do this with minimal assistance..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2ab0a-7f12-41c1-895f-7641313bb540",
   "metadata": {},
   "source": [
    "**Exercise:** convolve the test stimulus with the cell's STA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405bd4c3-5420-4dcc-b5de-24d654680fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb48101f-f6dc-4c82-8ab4-4fbb26da71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "test_convolved = convolve_stimulus_with_sta(test_stimulus[:1, :], sta)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8678356f-c9f6-44c1-a183-7136d8bf83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_convolved[:10]) # first ten bins\n",
    "print(test_convolved[-10:]) # last ten bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4eaedb-f0bd-4f56-949b-d91ebec041f8",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "[ 9.83264254 11.59203491 11.18314166  7.05552873  4.8746515   0.88349744\n",
    " -2.08094665 -0.36610227  2.49119166  6.88311984]\n",
    "[13.84409797 14.3960606  12.22459318  8.37844131  5.54077512  3.10056181\n",
    "  4.43419756  4.72008878  3.45400087  0.59254138]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baf68d7-750f-430f-9d21-da9c1275eeab",
   "metadata": {},
   "source": [
    "**Exercise:** compute the predicted responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c9cab9-b125-4d1f-8807-aa057d2b2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66fea7-212a-47e3-8b45-43667ae18b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "y_predicted = exponential(test_convolved, *optimal_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c97f1ba-dd56-4b1b-9934-86bf7e9c2498",
   "metadata": {},
   "source": [
    "Amazing! Now it's time to see if what you predicted looks anything like the ground truth!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2bd402-4e56-4932-9d03-93ef0915fb81",
   "metadata": {},
   "source": [
    "**Drumroll...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d9c3c-5844-4099-bf85-424fbe7ffcca",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501066a8-01c4-4b68-b37f-6d4f0af324a8",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e5810c-b351-43c9-8515-d7c75e085a7b",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b148fe47-7e99-4cbe-b076-c0ddfa6e70e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 4), layout=\"constrained\")\n",
    "ax.plot(ground_truth[num_past_pulses-1:], lw=3, c=\"tab:blue\", label=\"ground truth\") \n",
    "## NOTE: we truncated the ground truth above\n",
    "\n",
    "ax.plot(y_predicted, lw=3, c=\"tab:red\", label=\"predicted\")\n",
    "ax.set_xlabel(\"time bins\")\n",
    "ax.set_ylabel(\"spike count per bin\")\n",
    "ax.set_title(\"ground truth vs prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed81ad3f-0ea6-4576-b37e-5d9685a46e89",
   "metadata": {},
   "source": [
    "**Ta Da!!!**\n",
    "\n",
    "Surprised? Disappointed?\n",
    "\n",
    "Well, clearly, the predicted traces do follow the \"tendency\" of the ground truth, but don't quite manage to find the same amplitude in the peaks, nor find the quietness of the flats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dbb4b8-5a45-4ec3-aaa9-3e056b1ee4c4",
   "metadata": {},
   "source": [
    "You can quantify the similarity between the predicted traces and ground truth using the **Pearson's correlation coefficient**, or **Pearson's R**. For this, you will use another `scipy` function called `pearsonr`, that's also been imported for you already."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a052f-b56b-4045-b98d-f50b35844151",
   "metadata": {},
   "source": [
    "**Exercise:** compute the Pearson's R between the predicted responses and ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e7f35e-a475-4e2c-98e5-9cfc0272d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0e6e7e-46d1-49b7-9874-4463219f1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "r_value = pearsonr(ground_truth[num_past_pulses-1:], y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33bc35-64b9-46ca-8880-2d172a56cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_value)  # THIS RESULT MAY DIFFER FOR YOU, BUT IT SHOULD BE CLOSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5253a11c-e131-49d8-a477-a8b160ca6f12",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "PearsonRResult(statistic=0.8343205916332544, pvalue=2.1298152908910366e-145)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3dba29-505b-4394-84a1-88ccda3de495",
   "metadata": {},
   "source": [
    "Well, maybe that is surprising for you? The **correlation coefficient between the two signals is pretty high**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f133d15f-a1ab-474b-9b13-fbac921495dd",
   "metadata": {},
   "source": [
    "You might argue that this statistic is misleading, and you wouldn't be entirely wrong. The **correlation coefficient is sensitive to the location of the peaks and troughs in two signals, but not so much to their relative amplitudes**. As a result, our predicted trace gets a pretty high r-value, even though it clearly falls short of predicting the cell's peaks of activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e325e07-6ee0-4246-87e5-e5f527ad7d3a",
   "metadata": {},
   "source": [
    "This means that it's **important to look at the actual traces and not just the statistics** to determine how good or bad a model is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0618ccc6-f54b-4ca4-8327-722059400ea3",
   "metadata": {},
   "source": [
    "It also means that our current implementation of the LN model is far from perfect at predicting (at least this cell's) responses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51277c5e-dc5c-446f-a7b4-95084f664fad",
   "metadata": {},
   "source": [
    "However, we'd also like to argue that this is **already fantastic for a model which took you one day to implement with limited experience in Python programming**. Where more sophisticated models might win in better predictive power, the LN model wins in simplicity and clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5761f4-d48d-4699-bfb2-6ab246f53698",
   "metadata": {},
   "source": [
    "The last thing to do now is to apply this model to other cells and examine the differences in model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6b0fc-a303-4f65-adc0-c3474a8c77b7",
   "metadata": {},
   "source": [
    "# 8 - Multiple Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7e9a43-97c1-43c2-a826-7e05ed158cf5",
   "metadata": {},
   "source": [
    "Before you repeat this process for multiple cells, it would be best to implement a function for this. \n",
    "\n",
    "This will be a **big function**, and you'll have to implement it carefully. The function needs to have the following properties:\n",
    "\n",
    "1. It implements the LN model for a single cell\n",
    "2. It takes as input the spike times, stimuli, pulses, number of past frames for the sta, number of test and training frames, the fitting function, fit bounds and inital fit parameters\n",
    "3. It returns a **python dictionary** containing the following keys - `prediction`, `ground_truth`,`r_val`, `fit_parameters` and `sta`\n",
    "4. Internally, it repeats all the steps from the `calculate_sta` function. Ideally we would use the calculate_sta function directly, but many of the steps used in that function need to be repeated here as well. So feel free to copy the internals of the `calculate_sta` function and paste them inside this function, taking care that you're using the right variables. (it's perfectly fine if you choose not to do this, but you'll be recalculating many of the variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ec599-1213-4215-b2a8-f415484caab6",
   "metadata": {},
   "source": [
    "**Exercise:** complete the following function that implements the LN model for a single cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c793be78-4c17-47fd-b9a7-f530a684b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECK FOR MISSING LINES IN CODE AND COMPLETE THEM ##\n",
    "\n",
    "def ln_model(\n",
    "    spike_times_array,\n",
    "    stimulus_array,\n",
    "    pulses_array, \n",
    "    training_frames,\n",
    "    test_frames,\n",
    "    past_frames,\n",
    "    fit_function,\n",
    "    fit_bounds,\n",
    "    init_params,\n",
    "):\n",
    "    # reshape the stimulus and pulses using the training_frames and test_frames\n",
    "    stimulus_reshaped, pulses_reshaped = \n",
    "    \n",
    "    # select only those spikes which occur during the stimulus presentation\n",
    "    spikes_in_stimulus = spike_times_array[  # select...\n",
    "        (   ) &  # ... all spikes after the first pulse\n",
    "        (   )  # ... and all spikes before the last pulse\n",
    "    ]\n",
    "    \n",
    "    # bin the spike train using the reshaped pulses\n",
    "    spikes_binned = \n",
    "    \n",
    "    # reshape the binned spikes to the same shape as reshaped_pulses\n",
    "    spikes_in_trials = \n",
    "    \n",
    "    # split spikes into training and test\n",
    "    training_spikes, test_spikes = \n",
    "    \n",
    "    # split stimulus into training and test\n",
    "    training_stimulus, test_stimulus = \n",
    "    \n",
    "    # get stimulus snippets past_frames before each spike\n",
    "    stimulus_snippets = \n",
    "    \n",
    "    # average over the stimulus snippets\n",
    "    sta = \n",
    "    \n",
    "    # normalize the sta\n",
    "    \n",
    "    \n",
    "    # compute the ground truth responses\n",
    "    ground_truth = \n",
    "    \n",
    "    # convolve the training stimulus with the sta\n",
    "    convolved_training = \n",
    "    # convolve the test stimulus with the sta\n",
    "    convolved_test =     \n",
    "    \n",
    "    # compute fit parameters\n",
    "    fit_parameters, _ = curve_fit(\n",
    "        f=             # the function we'd like to fit\n",
    "        xdata=         # x axis values\n",
    "        ydata=         # y axis values\n",
    "        p0=            # initial parameters\n",
    "        bounds=        # bounds\n",
    "        maxfev=4000,   # just making sure the algorithm converges, hehe\n",
    "    )\n",
    "    \n",
    "    # run the prediction on convolved_test using the fit_parameters\n",
    "    prediction = \n",
    "    \n",
    "    # compute pearson's r\n",
    "    r_val = \n",
    "    \n",
    "    # store results\n",
    "    result_dict = {\n",
    "        \"prediction\": prediction,\n",
    "        \"ground_truth\": ground_truth[past_frames-1:],\n",
    "        \"r_val\": r_val.statistic,\n",
    "        \"fit_parameters\": fit_parameters,\n",
    "        \"sta\": sta,\n",
    "    }\n",
    "    \n",
    "    return result_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886de7f1-d643-4ca9-9e49-49e8da401bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "def ln_model(\n",
    "    spike_times_array,\n",
    "    stimulus_array,\n",
    "    pulses_array, \n",
    "    training_frames,\n",
    "    test_frames,\n",
    "    past_frames,\n",
    "    fit_function,\n",
    "    fit_bounds,\n",
    "    init_params,\n",
    "):\n",
    "    # reshape the stimulus and pulses using the training_frames and test_frames\n",
    "    stimulus_reshaped, pulses_reshaped = get_reshaped_stimulus_and_pulses(\n",
    "        stimulus_array,\n",
    "        pulses_array,\n",
    "        training_frames,\n",
    "        test_frames\n",
    "    )\n",
    "    \n",
    "    # select only those spikes which occur during the stimulus presentation\n",
    "    spikes_in_stimulus = spike_times_array[  # select...\n",
    "        (spike_times_array > pulses_reshaped.ravel()[0]) &  # ... all spikes after the first pulse\n",
    "        (spike_times_array < pulses_reshaped.ravel()[-1])  # ... and all spikes before the last pulse\n",
    "    ]\n",
    "    \n",
    "    # bin the spike train using the reshaped pulses\n",
    "    spikes_binned = compute_binned_spikes(\n",
    "        spikes_in_stimulus,\n",
    "        pulses_reshaped\n",
    "    )\n",
    "    \n",
    "    # reshape the binned spikes to the same shape as reshaped_pulses\n",
    "    spikes_in_trials = np.reshape(spikes_binned, reshaped_pulses.shape)\n",
    "    \n",
    "    # split spikes into training and test\n",
    "    training_spikes, test_spikes = split_into_two(\n",
    "        spikes_in_trials,\n",
    "        training_frames\n",
    "    )\n",
    "    \n",
    "    # split stimulus into training and test\n",
    "    training_stimulus, test_stimulus = split_into_two(\n",
    "        stimulus_reshaped,\n",
    "        training_frames\n",
    "    )\n",
    "    \n",
    "    # get stimulus snippets past_frames before each spike\n",
    "    stimulus_snippets = get_stimulus_stack(\n",
    "        training_spikes,\n",
    "        training_stimulus,\n",
    "        past_frames\n",
    "    )\n",
    "    \n",
    "    # average over the stimulus snippets\n",
    "    sta = stimulus_snippets.mean(axis=0)\n",
    "    \n",
    "    # normalize the sta\n",
    "    sta /= sta.std()\n",
    "    \n",
    "    # compute the ground truth responses\n",
    "    ground_truth = test_spikes.mean(axis=0)\n",
    "    \n",
    "    # convolve the training stimulus with the sta\n",
    "    convolved_training = convolve_stimulus_with_sta(training_stimulus, sta)\n",
    "    # convolve the test stimulus with the sta\n",
    "    convolved_test = convolve_stimulus_with_sta(test_stimulus[:1, :], sta)[0]\n",
    "    \n",
    "    # compute fit parameters\n",
    "    fit_parameters, _ = curve_fit(\n",
    "        f=fit_function,  # the function we'd like to fit\n",
    "        xdata=convolved_training.ravel(),  # x axis values\n",
    "        ydata=training_spikes[:, past_frames - 1:].ravel(),  # y axis values\n",
    "        p0=init_params,  # initial parameters\n",
    "        bounds=fit_bounds,  # bounds\n",
    "        maxfev=4000,  # just making sure the algorithm converges, hehe\n",
    "    )\n",
    "    \n",
    "    # run the prediction on convolved_test using the fit_parameters\n",
    "    prediction = fit_function(convolved_test, *fit_parameters)\n",
    "    \n",
    "    # compute pearson's r\n",
    "    r_val = pearsonr(ground_truth[past_frames-1:], prediction)\n",
    "    \n",
    "    # store results\n",
    "    result_dict = {\n",
    "        \"prediction\": prediction,\n",
    "        \"ground_truth\": ground_truth[past_frames-1:],\n",
    "        \"r_val\": r_val.statistic,\n",
    "        \"fit_parameters\": fit_parameters,\n",
    "        \"sta\": sta,\n",
    "    }\n",
    "    \n",
    "    return result_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279555dc-bc51-404a-9e23-e30c5fdbb73d",
   "metadata": {},
   "source": [
    "There is no easy way to test if this function is correctly implemented, so best to run this on the all the cells and see if there are any errors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290ff3e-96b4-4346-94d6-99bdbcb02934",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "filepaths = sorted(Path('data_LN_model').glob('fullfieldnoise*.txt'))\n",
    "\n",
    "for filepath in filepaths:\n",
    "    # load spike times for each cell\n",
    "    spike_times = np.loadtxt(filepath)\n",
    "    \n",
    "    result = ln_model(\n",
    "        spike_times_array=spike_times,\n",
    "        stimulus_array=stimulus,\n",
    "        pulses_array=pulses,\n",
    "        training_frames=nframes_training,\n",
    "        test_frames=nframes_test,\n",
    "        past_frames=num_past_pulses,\n",
    "        fit_function=exponential,\n",
    "        fit_bounds=([0, -np.inf, -np.inf], np.inf),\n",
    "        init_params=[2.0, 0.5, -1.5],\n",
    "    )\n",
    "    \n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a736155-7030-4e01-9dc5-1f978bbd9be9",
   "metadata": {},
   "source": [
    "If the cell above ran without an issue, **congratulations**! You have successfully implemented the LN model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb808fa9-4cc2-462b-861b-5d7df3de13ec",
   "metadata": {},
   "source": [
    "It's now time to plot results for all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf00a3-cb33-441f-af3f-b61c5813a9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=4, ncols=2, layout=\"constrained\", sharex=True, sharey=True, figsize=(15, 15))\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    ax = axs.flat[i]\n",
    "    \n",
    "    ax.plot(result[\"ground_truth\"], lw=2, c=\"tab:blue\")\n",
    "    ax.plot(result[\"prediction\"], lw=2, c=\"tab:red\")\n",
    "    ax.set_title(f\"cell {i+1}, pearson's r: {result['r_val']:.2f}\")\n",
    "    \n",
    "    if i % 2 == 0:\n",
    "        ax.set_ylabel(\"avg. spike count\")\n",
    "    \n",
    "    if i > 5:\n",
    "        ax.set_xlabel(\"time bins\")\n",
    "\n",
    "plt.suptitle(\"LN model: ground truth (blue) vs prediction (red)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa15e5ae-d51e-42df-8973-ed556f7f3e7c",
   "metadata": {},
   "source": [
    "Altogether, these plots look very promising! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdc4e51-dc44-4f69-97c3-aab40478a713",
   "metadata": {},
   "source": [
    "For a model that makes very few assumptions and is easy to implement, it was able to predict the responses of these cells remarkably well! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d93a9-ab13-42ec-aeb1-1b60db26267d",
   "metadata": {},
   "source": [
    "Here's a final summary, and some notes:\n",
    "\n",
    "1. You implemented (probably) your first model that predicts the responses of retinal ganglion cells. You tested this on a full-field flicker stimulus, although there is nothing inherently preventing the model from predicting responses to other full field stimuli, assuming you have the cell's STA to begin with. \n",
    "2. In the process, you learnt how to manipulate a variety of python data structures, and we hope that you're feeling more confident with your pythonic abilities now!\n",
    "3. We deliberately did not go into how to make scientific figures in Python using matplotlib because that is a whole (and much longer) course unto itself. However, the example plots in this tutorial (and the previous ones) should have given you a good idea of how to start!\n",
    "4. We didn't always follow the best Python coding practices in this tutorial (or the others), but we encourage you to keep those in mind when writing Python code. It will help keep your code organized and efficient. For further reading, you can go through [this very nice tutorial](https://docs.python-guide.org/writing/style/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80a2e0-8a6a-469e-9ded-fb6ff1a32136",
   "metadata": {},
   "source": [
    "**If you're done with the tutorial quickly and feel like tackling a few more (slightly involved) coding exercises, feel free to go on with the optional section below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73046338-6c38-44fa-8c66-819e3944241a",
   "metadata": {},
   "source": [
    "# 9 - Different Nonlinearity (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3244041-7de2-44de-8274-ac4c3a7a43f0",
   "metadata": {},
   "source": [
    "In the model so far, we used a parametrized exponential to fit the nonlinear relationship between the convolution output and the spiking response of the cell. There are, like was mentioned before, many other functions you can use for the fit. Let's look at one other function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559dd83a-d8c5-42fa-969f-016b449e8248",
   "metadata": {},
   "source": [
    "### Softplus Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a33e66f-fbec-48f7-851e-df669cafd396",
   "metadata": {},
   "source": [
    "The function we'll use looks like this:\n",
    "\n",
    "$$\n",
    "f(x) = a \\cdot \\log(1 + \\exp(b \\cdot x + c))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36061bc1-49ff-4c59-9ebd-3c7b47f6b7d6",
   "metadata": {},
   "source": [
    "This is the *softplus function*. It has some desirable properties:\n",
    "\n",
    "* At large positive values of x, where $\\exp(b \\cdot x + c) \\gg 1$, the function is linear\n",
    "* At large negative values of x, where $\\exp(b \\cdot x + c) \\rightarrow -\\infty$, the function output tends to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ffcf9-bb01-41ae-860e-1995edc1e232",
   "metadata": {},
   "source": [
    "If you're familiar with the field of deep learning, the softplus function is used as a rectifier in neural networks as a smoother counterpart to the ReLU. It has a soft threshold (determined by the output of the function approx. where $b \\cdot x + c = 0$). Below this threshold, the function's output rapidly converged to 0.0, and beyond this threshold, it's output quickly becomes linear. Let's see if this is better than our simple parametrized exponential in capturing the cells' spiking activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5372ded2-b4ee-4d61-bc59-a0487c6f5c3f",
   "metadata": {},
   "source": [
    "To that end, first define the function!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06574af0-3989-4b85-981f-86ec83d5d63e",
   "metadata": {},
   "source": [
    "**Exercise:** define the `softplus` function, that takes as input `x`, followed by `a`, `b` and `c`. **The order of the arguments is important.** Internally, make use of the fact that the input `x` is a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213c7407-96b0-4692-980f-c321c2864fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa91d59-d4fd-4dff-a96d-3dce2a625541",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "def softplus(x, a, b, c):\n",
    "    \"\"\"\n",
    "    Vectorized implementation of the softplus function.\n",
    "    \"\"\"\n",
    "    return a * np.log(1 + np.exp(b * x + c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ed5657-a2d5-446d-ab26-e2326e37f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(softplus(np.arange(-5, 5), 0.5, 0.5, -0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cecfbb-56db-408e-b6d5-ab3b17906b29",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "[0.02429368 0.03944487 0.06346401 0.10070664 0.15663084 0.23703849\n",
    " 0.34657359 0.48703849 0.65663084 0.85070664]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab4d6e-2d39-4db9-be9e-1ea867b72bac",
   "metadata": {},
   "source": [
    "Excellent!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080dc072-5f4a-46c6-ba12-e897d56251e7",
   "metadata": {},
   "source": [
    "In fact, before you go on to fit the data to this function, go ahead and plot it for a range of values. Feel free to play around with the values of `a`, `b` and `c` to get an intuition of what each parameter does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a19bffd-c011-47b4-963f-33b4b8bb6ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_x = np.linspace(-20, 20, 200)\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "ax.plot(dummy_x, softplus(x_values, 1., 1., 0.0), lw=3, label=\"softplus\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ecfafa-ce69-4923-ab40-5f5ececc75a4",
   "metadata": {},
   "source": [
    "Alright, now you're ready to fit it to our data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b37580-35f0-4d19-ae36-352cedf69981",
   "metadata": {},
   "source": [
    "**Exercise:** just like you did before for the `exponential`, find optimal parameters for the `softplus` function using `curve_fit`\n",
    "\n",
    "*Note:* the bounds remain the same as for the `exponential` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b5a1b-467e-4dfd-aff2-e84be8234aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILL IN THE MISSING ARGUMENTS ##\n",
    "\n",
    "optimal_parameters_softplus, _ = curve_fit(\n",
    "    f=,  # the function you'd like to fit\n",
    "    xdata=  # x axis values\n",
    "    ydata=  # y axis values\n",
    "    p0=[2.0, 0.5, -1.5],  # initial parameters\n",
    "    bounds=([0, -np.inf, -np.inf], np.inf),  # bounds\n",
    "    maxfev=4000,  # just making sure the algorithm converges, hehe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a41c281-9db0-4b99-9f3b-c89afd946e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "optimal_parameters_softplus, _ = curve_fit(\n",
    "    f=softplus,  # the function we'd like to fit\n",
    "    xdata=convolved_signal.ravel(),  # x axis values\n",
    "    ydata=training_spikes[:, num_past_pulses - 1:].ravel(),  # y axis values\n",
    "    p0=[0.05, 0.90, -3.0],  # initial parameters\n",
    "    bounds=([0, -np.inf, -np.inf], np.inf),  # bounds\n",
    "    maxfev=4000,  # just making sure the algorithm converges, hehe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7bd04e-6ce2-4778-8ea8-4668e8f708e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_parameters_softplus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f93ad66-f9dd-4d0b-9732-e8c57e7c3e03",
   "metadata": {},
   "source": [
    "Now, plot this for our data and compare it to the fit we got from the exponential function earlier!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c9d5d0-6bad-4bb0-b798-cd8e243fcf1a",
   "metadata": {},
   "source": [
    "**Exercise:** complete the code to compute `y_fit_softplus`, feeding `x_values` we used earlier and using `optimal_parameters` as input to the softplus function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a765ce-ecfe-4240-87e8-5545125c270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPLETE THE FOLLOWING LINE ##\n",
    "\n",
    "y_fit_softplus = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f7574-b2ab-4820-b31d-4dd817224132",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "y_fit_softplus = softplus(x_values, *optimal_parameters_softplus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c979d30-6391-48f6-a726-0043a08235c8",
   "metadata": {},
   "source": [
    "Time to see the plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5485a3c6-f64c-4bf5-8049-11d66a53b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "ax.scatter(convolved_signal.ravel(), training_spikes[:, num_past_pulses-1:].ravel(), c=\"tab:green\", s=2)\n",
    "ax.plot(x_values, y_fit_softplus, lw=3, c=\"tab:blue\", label=\"softplus fit\")\n",
    "ax.plot(x_values, y_fit, lw=3, c=\"tab:orange\", label=\"exp. fit\")\n",
    "ax.set_xlabel(\"Values in the Convolved Signal\")\n",
    "ax.set_ylabel(\"Spike Count\")\n",
    "ax.set_title(\"Relationship between the convolved signal and spike counts\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b329e71-edf3-4082-9ab5-5aad30f058ba",
   "metadata": {},
   "source": [
    "Does that look better or worse than the exponential? Why?\n",
    "\n",
    "Think about whether you'd expect this fit to yield better or worse predictions on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac26c06-5462-4e3e-873a-6205e24f8343",
   "metadata": {},
   "source": [
    "Next, use the model to predict responses on the test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9bd9d-f3aa-4453-9afb-f4f61d53dfe3",
   "metadata": {},
   "source": [
    "**Exercise:** as you did earlier, complete the code to compute the predicted traces using the optimal parameters from the softplus function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a16722f-9c5d-4e44-8584-6d1f33e92cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPLETE THE FOLLOWING LINE OF CODE ##\n",
    "\n",
    "y_predicted_softplus = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef0cfe8-227e-4f1c-85bb-f47a8c3eefd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION ##\n",
    "\n",
    "y_predicted_softplus = softplus(test_convolved, *optimal_parameters_softplus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfb48d8-909f-480b-9600-eb80ad9c69d7",
   "metadata": {},
   "source": [
    "Okay, let's plot our predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05410bd2-163f-43fc-8d46-4da14d4356b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 4), layout=\"constrained\")\n",
    "ax.plot(ground_truth[num_past_pulses-1:], lw=2, c=\"tab:blue\", label=\"ground truth\") \n",
    "## NOTE: we truncated the ground truth above\n",
    "\n",
    "ax.plot(y_predicted, lw=2, c=\"tab:red\", label=\"exp. fit\")\n",
    "ax.plot(y_predicted_softplus, lw=2, c=\"tab:green\", label=\"softplus fit\")\n",
    "ax.set_xlabel(\"time bins\")\n",
    "ax.set_ylabel(\"spike count per bin\")\n",
    "ax.set_title(\"ground truth vs prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ef9bde-7ff3-4c65-b591-e80f62650982",
   "metadata": {},
   "source": [
    "Are you surprised? Is this what you expected after plotting the nonlinearities earlier?\n",
    "\n",
    "Examine the different traces. What differences do you notice? Where does softplus function do better than the exponential? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4758abfd-66f8-4982-b6c6-f15ca4c285c8",
   "metadata": {},
   "source": [
    "It appears that the exponential causes the model to fire more frequently, causing the predictions to differ from the ground truth in regions where the cell was quiet. The softplus handles that better because all convolution values below the soft threshold yield an output of ~0 spikes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9816b295-2405-4acb-a413-81c81df130ed",
   "metadata": {},
   "source": [
    "Let's do a more quantitative comparison of the two model outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb7d1e0-f79c-45c7-8a9d-62e5b25916c9",
   "metadata": {},
   "source": [
    "**Exercise:** compute the Pearson's R for the prediction obtained using a softplus function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7533fa85-8481-4247-8b92-341f7b1a0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "r_value_softplus = \n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4121c0-6c58-4d67-81f0-cc78451d2dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "\n",
    "r_value_softplus = pearsonr(ground_truth[num_past_pulses-1:], y_predicted_softplus)\n",
    "\n",
    "## END CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726f8e2-29b9-40d4-8d93-a526bac82dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_value_softplus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38981fcb-366a-4c12-880c-df6422b7b763",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "PearsonRResult(statistic=0.8684321885416403, pvalue=6.23269076181971e-171)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69da2f27-28ef-458b-beb5-f150b9bab8a7",
   "metadata": {},
   "source": [
    "Nice work! By simply changing the non-linearity, you increased the model's accuracy by a few percentage points!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a161a8-8b72-4e32-a634-4907c4a4886f",
   "metadata": {},
   "source": [
    "Let's see if this is the case across all cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa71f6b-895b-4df4-b336-1621d409dee1",
   "metadata": {},
   "source": [
    "First, let's run the LN model for all cells again, but this time using the softplus function instead of the exponential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63df12f9-c047-496f-a787-ce6931b883bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_softplus = []\n",
    "\n",
    "filepaths = sorted(Path('data_LN_model').glob('fullfieldnoise*.txt'))\n",
    "\n",
    "for filepath in filepaths:\n",
    "    # load spike times for each cell\n",
    "    spike_times = np.loadtxt(filepath)\n",
    "    \n",
    "    result = ln_model(\n",
    "        spike_times_array=spike_times,\n",
    "        stimulus_array=stimulus,\n",
    "        pulses_array=pulses,\n",
    "        training_frames=nframes_training,\n",
    "        test_frames=nframes_test,\n",
    "        past_frames=num_past_pulses,\n",
    "        fit_function=softplus,  # THE ONLY THING NEW IN THIS CELL IS THE NON-LINEARITY\n",
    "        fit_bounds=([0, -np.inf, -np.inf], np.inf),\n",
    "        init_params=[0.05, 0.9, -3.0],\n",
    "    )\n",
    "    \n",
    "    results_softplus.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b04475-f188-497d-a201-7174e2558df3",
   "metadata": {},
   "source": [
    "And now, let's plot the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1138aab-a4c5-4799-b529-a976a2b783ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=4, ncols=2, layout=\"constrained\", sharex=True, sharey=True, figsize=(15, 10))\n",
    "\n",
    "for i, (exp_res, sp_res) in enumerate(zip(results, results_softplus)):\n",
    "    ax = axs.flat[i]\n",
    "    \n",
    "    ax.plot(exp_res[\"ground_truth\"], lw=1, c=\"tab:blue\")\n",
    "    ax.plot(exp_res[\"prediction\"], lw=1, c=\"tab:red\")\n",
    "    ax.plot(sp_res[\"prediction\"], lw=1, c=\"tab:green\")\n",
    "    ax.set_title(\n",
    "        f\"cell {i+1}, \"\n",
    "        f\"exp. r: {exp_res['r_val']:.2f}, \"\n",
    "        f\"softplus r: {sp_res['r_val']:.2f}\"\n",
    "    )\n",
    "    \n",
    "    if i % 2 == 0:\n",
    "        ax.set_ylabel(\"avg. spike count\")\n",
    "    \n",
    "    if i > 5:\n",
    "        ax.set_xlabel(\"time bins\")\n",
    "\n",
    "plt.suptitle(\"LN model: ground truth (blue) vs exp. prediction (red) vs softplus prediction (green)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6342a8-f7ed-4e67-81f6-3935e6fdccfb",
   "metadata": {},
   "source": [
    "Nice! The model output across the cells is in fact better when using the softplus. In all cases, you notice that the softplus allows for a lower spike count than the exponential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e24d6-3a49-423d-9363-29d61b6915f9",
   "metadata": {},
   "source": [
    "However, what is also interesting to see is that the softplus allows the model to reach a slightly higher spike response for many of the peaks in the ground truth data, as compared to the exponential. This is despite the fact that for higher values of the convolution output, the exponential should yield larger spike responses (look at the non-linearity plot above). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a1c780-80b2-4e52-af37-03a13de2d3f9",
   "metadata": {},
   "source": [
    "In order to explain this, consider this final figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e61cfd1-aba9-4da9-b342-2f0a37daaf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "\n",
    "bin_ax = ax.twinx()\n",
    "bin_ax.hist(convolved_signal.ravel(), bins=x_values, color=(0.2, 0.2, 0.2, 0.2), label=\"training\", density=True)\n",
    "bin_ax.hist(test_convolved, bins=x_values, color=(0.0, 0.2, 1.0, 0.2), label=\"test\", density=True)\n",
    "\n",
    "bin_ax.set_ylabel(\"proportion of counts\")\n",
    "bin_ax.legend(loc=2)\n",
    "\n",
    "ax.scatter(convolved_signal.ravel(), training_spikes[:, num_past_pulses-1:].ravel(), c=\"tab:green\", s=2)\n",
    "ax.plot(x_values, y_fit_softplus, lw=3, c=\"tab:blue\", label=\"softplus fit\")\n",
    "ax.plot(x_values, y_fit, lw=3, c=\"tab:orange\", label=\"exp. fit\")\n",
    "\n",
    "ax.set_xlabel(\"Values in the Convolved Signal\")\n",
    "ax.set_ylabel(\"Spike Count\")\n",
    "ax.set_title(\"Relationship between the convolved signal and spike counts\")\n",
    "ax.legend(loc=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afadf26-ca39-4ea8-9bc2-ac752a45d6b1",
   "metadata": {},
   "source": [
    "This is almost the same plot as the non-linearity plots you created earlier, but overlaid with two histograms. The **gray histogram** is a distribution of convolved signal values from the **training set**, and the **blue histogram** is the distribution of convolved signal values from the **test set**. The height of the bars of the histograms don't have an absolute meaning, since the histogram counts have been normalized (so that they're easier to compare). In effect, the gray histogram shows the distribution of the green points on the x-axis.\n",
    "\n",
    "If you focus on the range of convolved signal values on the far right end of the x-axis, you'll notice that the **test set didn't contain any values beyond about 18**, whereas the training set did see values that were even larger (albeit more rarely). Also note that the fitted exponential curve exceeds the fitted softplus curve around about 18 on the x-axis, so the **test set doesn't contain stimuli that drive the cell to large responses like in the training set**.\n",
    "\n",
    "Lastly, consider the fact that the convolved signal has ~72000 data points as compared to the ~1800 of the test set. **Most of the values of the training set are concentrated around the central region on the x-axis**. Correspondingly, the green points (denoting the spike count for every training set bin) are heavily concentrated near the central region on the x-axis. Extreme convolved signal values are far, far fewer in number, suggesting that the **distribution of green points in the plot is visually misleading because it makes us feel like there are a significant number of green points corresponding to higher spike counts**.\n",
    "\n",
    "All of this leads to the following conclusions:\n",
    "\n",
    "1. the softplus fit yields slightly better predictions because it probably stays more true to the data in the central regions\n",
    "2. the softplus fit also *appears* to perform better because the test set doesn't really have stimuli that drive the cell to high firing rates, where the exponential might *actually yield better prediction*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c496c-2ef2-42c8-b16b-3812528fcc30",
   "metadata": {},
   "source": [
    "This analysis is, of course, specific to the cell we're studying and will vary slightly from cell to cell. But, the overall conclusions don't change so much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bad653-c57f-4949-8f61-7116a79d95a6",
   "metadata": {},
   "source": [
    "There are solutions to these issues, but you have covered enough in this course already. If you're interested, however, ask us and we should be able to give you more things to do!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
