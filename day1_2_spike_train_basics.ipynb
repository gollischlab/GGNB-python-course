{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of spike train analysis\n",
    "\n",
    "This is the first part of the course. \n",
    "\n",
    "**You will learn how to:** \n",
    "- Load spiking data into NumPy arrays and plot spike rasters.\n",
    "- Calculate firing rates from spike trains.\n",
    "- Calculate and interpret: interspike interval histograms, auto- and cross-correlograms.\n",
    "\n",
    "Let's first import the packages we are going to use, and set up some plotting parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.rc={'figure.figsize': (12, 6), 'font.size': 14 }\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Loading and plotting spike trains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A spike train of a single neuron can be defined as a set of spike times. \n",
    "\n",
    "We will beging by learning how to load the spike times of a single (or multiple) neurons in a numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading single and multiple spike trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_spikes_path = 'example_spikes.txt' #path of spike train in working folder\n",
    "example_spike_times = np.loadtxt(example_spikes_path) #load using the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file above contains the spike train of a single neuron in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_spike_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Since you will often have to load of spike trains, you should really understand how to do it. This exercise should also test your basic understanding of passing arguments to functions. Try to fill `load_spike_train()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spike_train(spike_train_path):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_train_path : string\n",
    "        File path to spike train text file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    spike_times : numpy.ndarray\n",
    "        Spike times\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    spike_times = np.loadtxt(spike_train_path)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return spike_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_spike_train('data_spike_trains/18_SP_C203.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "```python\n",
    "[  0.5766   2.8239   4.5523 ... 481.387  482.4371 482.4677]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** It is also useful to load multiple spike trains in our workspace. We would like to stack them in a list. Think of what should happen if the input is just a single spike train!\n",
    "\n",
    "*Hint:* Make use of `np.loadtxt()` that we used above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spike_trains_to_list(list_of_paths):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_paths : list of strings\n",
    "        File paths to the spike train text files\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list_of_spikes : list of numpy.ndarrays\n",
    "        Loaded spike trains\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    list_of_spikes = [np.loadtxt(spath) for spath in list_of_paths]\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return list_of_spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = 'data_spike_trains/'\n",
    "onlyfiles = [join(mypath, f) for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "print(load_spike_trains_to_list(onlyfiles)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "```python\n",
    "[3.710000e-02 5.223000e-01 5.517000e-01 ... 4.816942e+02 4.818235e+02\n",
    " 4.832769e+02]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raster plots for spike train visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An useful function for plotting spike trains is eventplot. Let's try plotting our example spikes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.eventplot(example_spike_times, colors='k')\n",
    "plt.xlim([0,15])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.yticks([1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you seen this plot before? Can you understand it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to use eventplot to stack spike trains on top of one another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = 'data_spike_trains/'\n",
    "onlyfiles = [join(mypath, f) for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "all_spike_trains = load_spike_trains_to_list(onlyfiles)\n",
    "plt.eventplot(all_spike_trains, colors='k', linelengths=0.8)\n",
    "plt.xlim([0,32]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took quite some time. The problem is that we first plotted the whole spike trains (up to 600 seconds), and then focused on the first 32 seconds. We can use logical indexing to shorten our spike trains just before plotting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "startTime = time.time()\n",
    "trains_to_plot = [all_spike_trains[ii][all_spike_trains[ii] < 32]\n",
    "                  for ii in range(0, len(all_spike_trains))]\n",
    "plt.eventplot(trains_to_plot, colors='k', linelengths=0.8)\n",
    "plt.show()\n",
    "endTime = time.time()\n",
    "print('Short spike trains took ' + str(endTime - startTime) + ' seconds')\n",
    "\n",
    "startTime = time.time()\n",
    "plt.eventplot(all_spike_trains, colors='k', linelengths=0.8)\n",
    "plt.xlim([0, 32])\n",
    "plt.show()\n",
    "endTime = time.time();\n",
    "print('Long spike trains took ' + str(endTime-startTime) + ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Let's test the basics. Can you plot the spike trains of five neurons from `all_spike_trains`? Specifically, 1st, 12th, 13th, 14th and 19th neurons...\n",
    "\n",
    "*Hint:* To match the raster above, focus on looking only at the first 32 seconds. You can use either of the two methods we showed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Idx = [0, 11,12,13,18]\n",
    "newList = [all_spike_trains[i][all_spike_trains[i] < 32] for i in Idx]\n",
    "plt.eventplot(newList, linelengths=0.8, colors='k');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Firing rate estimation by binning spike trains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spike trains almost never contain the same number of events. This fact makes their manipulation for plotting and analysis harder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning spike trains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create our bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmin = 0 # min time in seconds\n",
    "Tmax = 16 # max time in seconds\n",
    "dt = 0.01 # time bin in seconds\n",
    "binedges = np.arange(Tmin, Tmax+dt, dt)  # Include last right edge (+dt)\n",
    "bincenters = binedges[:-1] + dt/2 # get the centers of the bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And bin them using ```np.histogram```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frate,_ = np.histogram(example_spike_times, binedges) # do binning\n",
    "frate = frate / dt # transform counts to rates\n",
    "# plot results\n",
    "plt.plot(bincenters, frate)\n",
    "plt.xlim([0, Tmax])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Firing rate (Hz)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Let's put what we have learned in the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_firing_rate(spike_times, dt):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_times: numpy.ndarray\n",
    "        Spike train\n",
    "        \n",
    "    dt: float\n",
    "        Bin size in seconds\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    frate: numpy.ndarray\n",
    "        Firing rate in Hz\n",
    "\n",
    "    bincenters: numpy.ndarray\n",
    "        Bin centers in seconds\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    Tmax = spike_times.max()\n",
    "    Tmin = 0\n",
    "    binedges = np.arange(Tmin, Tmax+dt, dt)\n",
    "    bincenters = binedges[:-1] + dt/2 # get the centers of the bins\n",
    "    frate, _ = np.histogram(spike_times, binedges) # do binning\n",
    "    frate = frate / dt # transform counts to rates\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return frate, bincenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tshowmax = 10\n",
    "frate10, centers10 = calculate_firing_rate(example_spike_times[example_spike_times < tshowmax], 0.01)\n",
    "frate50, centers50 = calculate_firing_rate(example_spike_times[example_spike_times < tshowmax], 0.05)\n",
    "\n",
    "plt.plot(centers10, frate10, centers50, frate50)\n",
    "plt.xlim([0, tshowmax])\n",
    "plt.legend(('Bin 10 ms', 'Bin 50 ms'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we plotted the firing rate estimated with two different bin sizes. Can you understand this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Spike train statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at statistical properties of spike trains, we can extract useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-spike interval histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you see the inter-spike interval histogram of a single neuron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.diff(example_spike_times) * 1e3, np.linspace(0, 30, 100))\n",
    "plt.xlabel('ISI duration (ms)')\n",
    "plt.ylabel('# ISIs')\n",
    "plt.title('Inter-spike interval (ISI) histogram');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Estimate the % of intervals that are below 2 ms by filling in `percent_intervals(spike_times, time_interval)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_intervals(spike_times, time_interval):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_times : numpy.ndarray\n",
    "        Spike train\n",
    "\n",
    "    time_interval: float\n",
    "        Time interval\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pint : float\n",
    "        Percentage of ISIs below time_interval\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    spdiffs = np.diff(spike_times) * 1e3\n",
    "    pint = np.sum(spdiffs < time_interval) / spdiffs.size\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return pint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ISIs below 2 ms are', 100 * percent_intervals(example_spike_times,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```python\n",
    "1.15%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to construct an auto-correlogram, we have to bin our spike times first. Since we are looking at individual spikes, one has to use a time resolution of <1 ms. Furthermore, we will look only at timescales relevant for spiking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_res = 0.5e-3\n",
    "Tlag = 0.04\n",
    "Nlag = np.round(Tlag / t_res)\n",
    "bins = np.arange(0, 600, t_res)\n",
    "binnedspikes, binbin = np.histogram(example_spike_times, bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because NumPy's functions are not the best for our purpose, we will import an external library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycorrelate as pyc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the function ```pyc.ucorrelate()``` to calculate the autocorrelogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = pyc.ucorrelate(binnedspikes, binnedspikes, Nlag)\n",
    "ytoplot = np.hstack((np.flip(ac[1:]), 0, ac[1:])) / ac[0] # normalized by maximum\n",
    "xtoplot = np.arange(1, Nlag) * t_res * 1e3;\n",
    "xtoplot = np.hstack((-np.flip(xtoplot), 0, xtoplot))\n",
    "plt.plot(xtoplot, ytoplot)\n",
    "\n",
    "# Setup plot appearance\n",
    "plt.title('Autocorrelogram')\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('Correlation (norm.)')\n",
    "plt.xlim((-Tlag * 1e3, Tlag * 1e3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the autocorrelogram, we had to call multiple functions. Often, it helps to define a new function that can do the calculation for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Make the autocorrelogram calculation into a function! \n",
    "Bonus: think of how to add an extra option that plots the result as well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_auto_correlogram(spike_train, time_resolution, time_lag):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_train : numpy.ndarray\n",
    "        Array of spike times in seconds\n",
    "\n",
    "    time_resolution : float\n",
    "        Resolution in seconds\n",
    "\n",
    "    time_lag : float\n",
    "        Number of seconds of time lag\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xvals: numpy.ndarray\n",
    "        Array of times\n",
    "\n",
    "    yvals: numpy.ndarray\n",
    "        Array of autocorrelogram values\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    Nlag = np.round(time_lag / time_resolution)\n",
    "    bins = np.arange(0, np.max(spike_train), time_resolution)\n",
    "    binnedspikes, binbin = np.histogram(spike_train, bins)\n",
    "    ac = pyc.ucorrelate(binnedspikes, binnedspikes, Nlag)\n",
    "    yvals = np.hstack((np.flip(ac[1:]), 0, ac[1:])) / ac[0]\n",
    "    xvals = np.arange(1, Nlag) * time_resolution;\n",
    "    xvals = np.hstack((-np.flip(xvals), 0, xvals))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return yvals, xvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py, px = calculate_auto_correlogram(all_spike_trains[2], 1e-3, 40e-3)\n",
    "print(py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```python\n",
    "[0.05465071 0.06013122 0.0547279  0.05681204 0.06283288 0.05735237\n",
    " 0.05943651 0.05974527 0.0650714  0.06229255 0.06275569 0.06530297\n",
    "                        # ...\n",
    " 0.05943651 0.05735237 0.06283288 0.05681204 0.0547279  0.06013122\n",
    " 0.05465071]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(px, py)\n",
    "plt.title('Autocorrelogram')\n",
    "plt.xlabel('Time lag (s)')\n",
    "plt.ylabel('Correlation (norm.)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crosscorrelogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also correlate the spike trains of two different neurons. The resulting function is called the crosscorrelogram. By examing the crosscorrelogram, we can infer useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now fill in the following function that calculates the crosscorrelogram between spike_train1 and spike_train2. It should be similar as the autocorrelogram above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cross_correlogram(spike_train_1, spike_train_2, time_resolution, time_lag):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_train_1 : numpy.ndarray\n",
    "        Array of spike times in seconds\n",
    "    \n",
    "    spike_train_2 : numpy.ndarray\n",
    "        Array of spike times in seconds\n",
    "    \n",
    "    time_resolution : float\n",
    "        Resolution in seconds\n",
    "\n",
    "    time_lag : float\n",
    "        Number of seconds of time lag\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xvals: numpy.ndarray\n",
    "        Array of times\n",
    "\n",
    "    yvals: numpy.ndarray\n",
    "        Array of autocorrelogram values    \n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    Nlag = np.round(time_lag / time_resolution)\n",
    "    bins = np.arange(0, np.max((np.max(spike_train_1), np.max(spike_train_2))), time_resolution)\n",
    "    binnedspikes1, bb = np.histogram(spike_train_1, bins)\n",
    "    binnedspikes2, bb = np.histogram(spike_train_2, bins)\n",
    "    ac1 = pyc.ucorrelate(binnedspikes1, binnedspikes2, Nlag)\n",
    "    ac2 = pyc.ucorrelate(binnedspikes2, binnedspikes1, Nlag)\n",
    "    yvals = np.hstack((np.flip(ac2[1:]), ac1))\n",
    "\n",
    "    xvals = np.arange(1, Nlag) * time_resolution;\n",
    "    xvals = np.hstack((-np.flip(xvals), 0, xvals))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return yvals, xvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py, px = calculate_cross_correlogram(all_spike_trains[0], all_spike_trains[2], 0.5e-3, 60e-3) # pairs(0,2),\n",
    "\n",
    "plt.plot(px, py)\n",
    "plt.ylim([0, np.max(py)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we understand the cross-correlogram by looking at the spike trains?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Idx = [0, 2]\n",
    "newList = [all_spike_trains[i][all_spike_trains[i] < 32] for i in Idx]\n",
    "plt.eventplot(newList, linelengths=0.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Using the function from above, calculate and plot the cross-correlogram between the 3rd and 4th spike trains of ```allSpikeTrains```. How do you interpret what you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (approx. 2 lines)\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
