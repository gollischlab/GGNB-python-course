{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of spike train analysis\n",
    "\n",
    "This is the first part of the course. \n",
    "\n",
    "**You will learn how to:** \n",
    "- Load spiking data into NumPy arrays and plot spike rasters.\n",
    "- Calculate firing rates from spike trains.\n",
    "- Calculate and interpret: interspike interval histograms, auto- and cross-correlograms.\n",
    "\n",
    "Let's first import the packages we are going to use, and set up some plotting parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.rc={'figure.figsize': (12, 6), 'font.size': 14 }\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Loading and plotting spike trains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A spike train of a single neuron can be defined as a set of spike times. \n",
    "\n",
    "We will beging by learning how to load the spike times of a single neuron in a numpy array. We will then try to visualize the spike train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and plotting a single spike train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first examine the spike times file. NumPy offers a very easy way to load such a file in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_spikes_path = 'example_spikes.txt' #path of spike train in working folder\n",
    "example_spike_times = np.loadtxt(example_spikes_path) #load using the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file above contains the spike train of a single neuron in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(example_spike_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Can you print the shape and the maximum element of the ```example_spike_times``` array?\n",
    "\n",
    "*Hint:* ```np.shape()``` and ```np.max()``` may be handy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "print(np.shape(example_spike_times))\n",
    "print(np.max(example_spike_times))\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you understand what the meaning of your answers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Since you will often have to load of spike trains, you should really understand how to do it. This exercise should also test your basic understanding of passing arguments to functions. Try to fill `load_spike_train()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spike_train(spike_train_path):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_train_path : string\n",
    "        File path to spike train text file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    spike_times : numpy.ndarray\n",
    "        Spike times\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    spike_times = np.loadtxt(spike_train_path)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return spike_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_spike_train('data_spike_trains/18_SP_C203.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "```python\n",
    "[  0.5766   2.8239   4.5523 ... 481.387  482.4371 482.4677]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An useful function for plotting spike trains as a **raster plot** is ```plt.eventplot()```. Let's try plotting our ```example_spike_times```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.eventplot(example_spike_times);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot looks very dense, but we can focus only in a specific part to see the individual spikes. We can do that with ```plt.xlim()```!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.eventplot(example_spike_times)\n",
    "plt.xlim([0,10]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you seen this plot before? Can you understand it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use more Matplotlib functions to make our plot prettier and more informative. Let's try that below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.eventplot(example_spike_times,colors='black',linewidths=0.5)\n",
    "\n",
    "#add lims-labels\n",
    "plt.xlim([0,10])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.title('Raster plot');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and plotting multiple spike trains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also useful to load multiple spike trains in our workspace. A way to do that is by calling ```np.loadtxt()``` for each file separately, and putting them in a list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('spikes1')\n",
    "spikes1=np.loadtxt('data_spike_trains/18_SP_C101.txt')\n",
    "print(spikes1)\n",
    "\n",
    "print('spikes2')\n",
    "spikes2=np.loadtxt('data_spike_trains/18_SP_C203.txt')\n",
    "print(spikes2)\n",
    "\n",
    "print('spikes3')\n",
    "spikes3=np.loadtxt('data_spike_trains/18_SP_C603.txt')\n",
    "print(spikes3)\n",
    "\n",
    "print('spikeslist')\n",
    "spikeslist=[spikes1, spikes2, spikes3]\n",
    "print(spikeslist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this can get annoying very fast. Repeating code very often like the example above often indicates that we should think of a better way to solve our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An idea is to save the paths of the relevant spike trains in a list, and access them from there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = ['data_spike_trains/18_SP_C101.txt', 'data_spike_trains/18_SP_C203.txt', 'data_spike_trains/18_SP_C603.txt']\n",
    "\n",
    "spikes = np.loadtxt(path_list[2])\n",
    "print(spikes)\n",
    "\n",
    "spike_list=[np.loadtxt(path_list[0]), np.loadtxt(path_list[1]), np.loadtxt(path_list[2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Instead of having to do ```np.loadtxt()``` all the time, we can save our multiple spike trains in memory using another list! Given a list of paths, as the one above, return a list of spike trains! Think of what should happen if the input is just a single path!\n",
    "\n",
    "*Hint:* Make use of `np.loadtxt()` that we used above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spike_trains_to_list(list_of_paths):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_paths : list of strings\n",
    "        File paths to the spike train text files\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list_of_spikes : list of numpy.ndarrays\n",
    "        Loaded spike trains\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    list_of_spikes = [np.loadtxt(spath) for spath in list_of_paths]\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return list_of_spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = 'data_spike_trains/'\n",
    "onlyfiles = [join(mypath, f) for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "print(load_spike_trains_to_list(onlyfiles)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "```python\n",
    "[3.710000e-02 5.223000e-01 5.517000e-01 ... 4.816942e+02 4.818235e+02\n",
    " 4.832769e+02]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does one get such a list of paths efficiently? There are different options:\n",
    "- Put all the paths in a text file, and load it as a list\n",
    "- Read the paths directly into a list\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When checking our result, we used the second option. Let's look closely at how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = 'data_spike_trains/' # path where all the data files are\n",
    "\n",
    "filenames = listdir(mypath) # this function returns a list of filenames in mypath!\n",
    "\n",
    "# we need the full path for each element (like folder/folder/file)\n",
    "onlyfiles = []\n",
    "for fname in filenames:\n",
    "    onlyfiles.append(mypath+fname)\n",
    "\n",
    "all_spike_trains = load_spike_trains_to_list(onlyfiles) #best place to use our function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all our spike trains loaded in memory, in the list ```all_spike_trains```! We can now use eventplot to plot spike trains on top of one another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.eventplot(all_spike_trains, colors='k', linelengths=0.8, linewidths=0.5)\n",
    "\n",
    "plt.xlim([0,32])\n",
    "plt.title('Raster plot')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Neuron ID');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took quite some time. How much time exactly? The package ```time``` can help us find out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use it by running the exact same code snippet. The function ```time.time()``` returns the current time in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time() # start counter \n",
    "\n",
    "plt.eventplot(all_spike_trains, colors='k', linelengths=0.8, linewidths=0.5)\n",
    "plt.xlim([0, 32]) \n",
    "\n",
    "endTime = time.time() # end counter \n",
    "\n",
    "print('Plotting took ' + str(endTime-startTime) + ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wanted to focus on the first 32 s. Instead of plotting the entire length of all spike trains, we can generate a new list of shorter spike trains, and plot only that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time() # start counter \n",
    "\n",
    "trains_to_plot=[]\n",
    "for ii in range(0, len(all_spike_trains)):\n",
    "    long_train=all_spike_trains[ii]\n",
    "    trains_to_plot.append(long_train[long_train < 32])\n",
    "#trains_to_plot = [all_spike_trains[ii][all_spike_trains[ii] < 32] for ii in range(0, len(all_spike_trains))]\n",
    "\n",
    "plt.eventplot(trains_to_plot, colors='k', linelengths=0.8,linewidths=0.5)\n",
    "plt.xlim([0, 32])\n",
    "\n",
    "endTime = time.time() # end counter \n",
    "\n",
    "print('Plotting with short spike trains took ' + str(endTime - startTime) + ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you predict what would happen to the second plot if you change the xlims to [0, 64]?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Let's test some basics again! Can you plot the first 32 s of five spike trains from `all_spike_trains`? Specifically, we want the 1st, 12th, 13th, 14th and 19th neurons in the list...\n",
    "\n",
    "*Hint:* To match the raster above, focus on looking only at the first 32 seconds. You can use either of the two methods we showed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "Idx = [0, 11,12,13,18]\n",
    "newList = [all_spike_trains[ii][all_spike_trains[ii] < 32] for ii in Idx]\n",
    "plt.eventplot(newList, linelengths=0.8, colors='k',linewidths=0.5);\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Firing rate estimation by binning spike trains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spike trains almost never contain the same number of events. This fact makes their manipulation for plotting and analysis harder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning spike trains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create our bins..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmin = 0 # min time in seconds\n",
    "Tmax = 16 # max time in seconds\n",
    "dt = 0.01 # time bin in seconds\n",
    "\n",
    "binedges = np.arange(Tmin, Tmax+dt, dt)  # Include last right edge (+dt)\n",
    "bincenters = binedges[:-1] + dt/2 # get the centers of the bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(binedges[0:10])\n",
    "print(bincenters[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and use them to bin spikes with ```np.histogram()```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frate,_ = np.histogram(example_spike_times, binedges) # do binning\n",
    "print(frate[0:150])\n",
    "\n",
    "frate = frate / dt # transform counts to rates\n",
    "print(frate[0:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "plt.plot(bincenters, frate)\n",
    "plt.xlim([0, Tmax])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Firing rate (Hz)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Let's put what we have learned in the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_firing_rate(spike_times, dt, Tmin, Tmax):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_times: numpy.ndarray\n",
    "        Spike train\n",
    "        \n",
    "    dt: float\n",
    "        Bin size in seconds\n",
    "        \n",
    "    Tmin: float\n",
    "        Starting bin edge in seconds\n",
    "        \n",
    "    Tmax: float\n",
    "        Ending bin edge in seconds\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    frate: numpy.ndarray\n",
    "        Firing rate in Hz\n",
    "\n",
    "    bincenters: numpy.ndarray\n",
    "        Bin centers in seconds\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    binedges = np.arange(Tmin, Tmax+dt, dt)\n",
    "    bincenters = binedges[:-1] + dt/2 # get the centers of the bins\n",
    "    frate, _ = np.histogram(spike_times, binedges) # do binning\n",
    "    frate = frate / dt # transform counts to rates\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return frate, bincenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "tshowmin = 0\n",
    "tshowmax = 10\n",
    "dt1 = 0.01\n",
    "dt2 = 0.05\n",
    "\n",
    "#use function\n",
    "frate1, centers1 = calculate_firing_rate(example_spike_times, dt1, tshowmin, tshowmax)\n",
    "frate2, centers2 = calculate_firing_rate(example_spike_times, dt2, tshowmin, tshowmax)\n",
    "\n",
    "#plot results\n",
    "plt.plot(centers1, frate1)\n",
    "plt.plot(centers2, frate2)\n",
    "plt.xlim([0, tshowmax])\n",
    "\n",
    "#add legend\n",
    "plt.legend(('Bin size ' + str(dt1*1e3) +' ms', 'Bin size ' + str(dt2*1e3) +' ms'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code works, you should see the firing rate estimated with two different bin sizes. Can you understand this? You can also play around with the parameters in the cell above in order to understand binning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Spike train statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at statistical properties of spike trains, we can extract useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-spike interval histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you see the inter-spike interval histogram of a single neuron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all isis\n",
    "isis_array = np.diff(example_spike_times)\n",
    "\n",
    "#plot histogram\n",
    "plt.hist(isis_array * 1e3, np.linspace(0, 30, 100))\n",
    "\n",
    "#add lims & labels\n",
    "plt.xlim([0, 30])\n",
    "plt.xlabel('ISI duration (ms)')\n",
    "plt.ylabel('# ISIs')\n",
    "plt.title('Inter-spike interval (ISI) histogram');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the plot mean? How long is the absolute refractory period of a neuron?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to quantify the number of ISIs below a specific interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Estimate the % of intervals that are below ```time_interval``` (in ms) by filling in `percent_intervals(spike_times, time_interval)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_intervals(spike_times, time_interval):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_times : numpy.ndarray\n",
    "        Spike train\n",
    "\n",
    "    time_interval: float\n",
    "        Time interval\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pint : float\n",
    "        Percentage of ISIs below time_interval\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    spdiffs = np.diff(spike_times) * 1e3\n",
    "    pint = np.sum(spdiffs < time_interval) / spdiffs.size\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return pint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ISIs below 2 ms are', 100 * percent_intervals(example_spike_times,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```python\n",
    "1.150278293135436%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An approach we can take to construct an auto-correlogram, is to bin our spike times first. Since we are looking at individual spikes, one has to use a time resolution of <1 ms. Furthermore, we will look only at timescales relevant for spiking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_res = 0.0008\n",
    "Tlag = 0.04\n",
    "Tmax = 600\n",
    "\n",
    "Nlag = np.round(Tlag / t_res)\n",
    "bins = np.arange(0, Tmax, t_res)\n",
    "binnedspikes, binbin = np.histogram(example_spike_times, bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because NumPy's functions are not the best for our purpose, we will import an external library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycorrelate as pyc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the function ```pyc.ucorrelate()``` to calculate the autocorrelogram. Let's plot the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = pyc.ucorrelate(binnedspikes, binnedspikes, Nlag)\n",
    "plt.plot(ac);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the peak at 0 mean? In order to understand the auto-correlogram better, it would be nice to remove the peak and plot it in a symmetric fashion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peakremoved = ac[1:]\n",
    "ytoplot = np.hstack((np.flip(peakremoved), 0, peakremoved)) \n",
    "ytoplot = ytoplot/ ac[0] # normalized by maximum\n",
    "\n",
    "xtoplot = np.arange(1, Nlag) * t_res * 1e3;\n",
    "xtoplot = np.hstack((-np.flip(xtoplot), 0, xtoplot))\n",
    "\n",
    "plt.plot(xtoplot, ytoplot)\n",
    "\n",
    "# Setup plot appearance\n",
    "plt.title('Autocorrelogram')\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('Correlation (norm.)')\n",
    "plt.xlim((-Tlag * 1e3, Tlag * 1e3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the autocorrelogram in a nice format, we had to call multiple functions. Often, it helps to define a new function that can do the calculations for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Make the autocorrelogram calculation into a function! \n",
    "\n",
    "*Bonus:* think of how to add an extra option in the function that allows it to plot the result as well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_auto_correlogram(spike_train, time_resolution, time_lag):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_train : numpy.ndarray\n",
    "        Array of spike times in seconds\n",
    "\n",
    "    time_resolution : float\n",
    "        Resolution in seconds\n",
    "\n",
    "    time_lag : float\n",
    "        Number of seconds of time lag\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xvals: numpy.ndarray\n",
    "        Array of times\n",
    "\n",
    "    yvals: numpy.ndarray\n",
    "        Array of autocorrelogram values\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    Nlag = np.round(time_lag / time_resolution)\n",
    "    bins = np.arange(0, np.max(spike_train), time_resolution)\n",
    "    binnedspikes, binbin = np.histogram(spike_train, bins)\n",
    "    ac = pyc.ucorrelate(binnedspikes, binnedspikes, Nlag)\n",
    "    yvals = np.hstack((np.flip(ac[1:]), 0, ac[1:])) / ac[0]\n",
    "    xvals = np.arange(1, Nlag) * time_resolution;\n",
    "    xvals = np.hstack((-np.flip(xvals), 0, xvals))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return yvals, xvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py, px = calculate_auto_correlogram(all_spike_trains[2], 1e-3, 40e-3)\n",
    "print(py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```python\n",
    "[0.05465071 0.06013122 0.0547279  0.05681204 0.06283288 0.05735237\n",
    " 0.05943651 0.05974527 0.0650714  0.06229255 0.06275569 0.06530297\n",
    "                        # ...\n",
    " 0.05943651 0.05735237 0.06283288 0.05681204 0.0547279  0.06013122\n",
    " 0.05465071]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the result of your function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(px, py)\n",
    "plt.xlim((-40e-3, 40e-3));\n",
    "plt.title('Autocorrelogram')\n",
    "plt.xlabel('Time lag (s)')\n",
    "plt.ylabel('Correlation (norm.)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crosscorrelogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also correlate the spike trains of two different neurons. The resulting function is called the crosscorrelogram. By examing the crosscorrelogram, we can infer useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now fill in the following function that calculates the crosscorrelogram between spike_train1 and spike_train2. It should be similar as the autocorrelogram above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cross_correlogram(spike_train_1, spike_train_2, time_resolution, time_lag):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_train_1 : numpy.ndarray\n",
    "        Array of spike times in seconds\n",
    "    \n",
    "    spike_train_2 : numpy.ndarray\n",
    "        Array of spike times in seconds\n",
    "    \n",
    "    time_resolution : float\n",
    "        Resolution in seconds\n",
    "\n",
    "    time_lag : float\n",
    "        Number of seconds of time lag\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xvals: numpy.ndarray\n",
    "        Array of times\n",
    "\n",
    "    yvals: numpy.ndarray\n",
    "        Array of autocorrelogram values    \n",
    "    \"\"\"\n",
    "    \n",
    "    Nlag = np.round(time_lag / time_resolution)\n",
    "    bins = np.arange(0, np.max((np.max(spike_train_1), np.max(spike_train_2))), time_resolution)\n",
    "    binnedspikes1, bb = np.histogram(spike_train_1, bins)\n",
    "    binnedspikes2, bb = np.histogram(spike_train_2, bins)\n",
    "    ac1 = pyc.ucorrelate(binnedspikes1, binnedspikes2, Nlag)\n",
    "    ac2 = pyc.ucorrelate(binnedspikes2, binnedspikes1, Nlag)\n",
    "    yvals = np.hstack((np.flip(ac2[1:]), ac1))\n",
    "\n",
    "    xvals = np.arange(1, Nlag) * time_resolution;\n",
    "    xvals = np.hstack((-np.flip(xvals), 0, xvals))\n",
    "\n",
    "    return yvals, xvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our function works, we should be able to plot the crosscorrelogram of the 1st and 9th neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronIdx = [0, 8]\n",
    "\n",
    "spktrain1 = all_spike_trains[neuronIdx[0]]\n",
    "spktrain2 = all_spike_trains[neuronIdx[1]]\n",
    "\n",
    "py, px = calculate_cross_correlogram(spktrain1, spktrain2, 1e-3, 80e-3) # pairs(11,2),\n",
    "\n",
    "plt.plot(px, py)\n",
    "\n",
    "plt.xlim((-80e-3, 80e-3));\n",
    "plt.ylim([0, np.max(py)]);\n",
    "plt.title('Crosscorrelogram')\n",
    "plt.xlabel('Time lag (s)')\n",
    "plt.ylabel('Correlation (norm.)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we understand the cross-correlogram? Let's examine the spike trains..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newList = [all_spike_trains[ii][all_spike_trains[ii] < 16] for ii in neuronIdx]\n",
    "\n",
    "plt.eventplot(newList, linelengths=0.8,colors='black',linewidths=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Using the function from above, calculate and plot the cross-correlogram between the 3rd and 12th spike trains of ```all_spike_trains```. How do you interpret what you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (approx. 2 lines)\n",
    "py, px = calculate_cross_correlogram(all_spike_trains[2], all_spike_trains[11], 1e-3, 100e-3)\n",
    "plt.plot(px, py);\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
