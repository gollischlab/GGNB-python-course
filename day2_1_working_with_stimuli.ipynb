{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Stimuli\n",
    "\n",
    "So far we have learned how to load and handle spikes. Now we want to look at the stimuli eliciting the spikes to be able to investige the stimulus-response relationship of the recordings.\n",
    "\n",
    "**You will learn to:**\n",
    " - Align spike times to stimuli\n",
    " - Split spike times into multiple trials\n",
    " - Plot peristimulus time histogram (PSTH)\n",
    " - Compute and compare ON-OFF index among several cells\n",
    " \n",
    "Let's start again by importing relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.rc={'figure.figsize': (12, 6), 'font.size': 14 }\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - On-Off Stimulus\n",
    "\n",
    "We will take a look at a stimulus consisting of on-off steps in light intensity. This is roughly how the stimulus looks like.\n",
    "\n",
    "<img src=\"onoffsteps.gif\" width=\"200\">\n",
    "\n",
    "The information about the stimulus is stored in a text file. For this stimulus, the times of each step transition is provided in the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Load the stimulus step times from the file `filepath` in to the variable `stimulus`, like we have learned yesterday with the spike trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('data_on_off_steps/stimulus.txt')\n",
    "\n",
    "### START CODE HERE ###\n",
    "stimulus = np.loadtxt(filepath)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check if your code is correct\n",
    "print(stimulus[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**  \n",
    "`[10.0405 12.026299999999999 13.019200000000001 15.0051 15.998 ]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the loaded data, we will visualize them here with time versus light intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of cylcling intensities: 0.5, 1, 0.5, 0, 0.5, 1, 0.5, 0, ...\n",
    "intensities = np.tile([0.5, 1, 0.5, 0], len(stimulus)//4)\n",
    "\n",
    "plt.step(stimulus, intensities, where='post')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Light intesity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above shows the stimulus for the entire recording duration. It's not really easy to see the exact shape of the curve.\n",
    "\n",
    "**Exercise:** Using `plt.xlim`, show only two cycles of the stimulus. You might have to try different values. *Hint:* Use the `Shift+Tab` to understand the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.step(stimulus, intensities, where='post')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Light intesity')\n",
    "\n",
    "### START CODE HERE\n",
    "plt.xlim([10, 22]);\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Simulus Step Durations\n",
    "\n",
    "From the figure above we get a rough idea of stimulus. Since we are dealing with a repeating stimulus, we will treat each stimulus cycle as a trial. Each trial consists of four steps:\n",
    "\n",
    " 1. Mean grey step\n",
    " 1. On step\n",
    " 1. Mean grey step\n",
    " 1. Off step\n",
    "\n",
    "To obtain the number of trials, we divide the number of elements in the stimulus list by four:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = np.floor(stimulus.size / 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`num_trials` is now a float, but for later use we need it as integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = int(num_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to obtain the durations of the stimulus steps. The stimulus contains this information in the differences from one time event to the next, e.g. the difference between the first two elements is the duration of the first mean grey step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus[1] - stimulus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the durations of all stimulus steps we can use `np.diff`, which computes the difference between adjacent items in a list. To get the durations for the first trial, we take the differences of the first five elements:\n",
    "\n",
    "| Step           | Duration                    |\n",
    "| ----           | --------                    |\n",
    "| Mean grey step | `stimulus[1] - stimulus[0]` |\n",
    "| On step        | `stimulus[2] - stimulus[1]` |\n",
    "| Mean grey step | `stimulus[3] - stimulus[2]` |\n",
    "| Off step       | `stimulus[4] - stimulus[3]` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(stimulus[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since instruments might not always be precise in timing for each trial, we want to compute this duration for each trial and then average these durations.\n",
    "\n",
    "We start off by taking the differences of all adjacent elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = np.diff(stimulus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To easily average across trails, we reshape our list into a matrix of four columns by number of trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations.reshape(num_trials, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What went wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(durations) / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the differences of `n` elements, produces a list of `n-1` elements. For the last trial, the last duration is missing. So, we'll exclude this trial from our average, by removing the last three elements from `durations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = durations[:-3]\n",
    "durations = durations.reshape(num_trials - 1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look: We have the step durations in the columns for each trial in the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations[:10]  # Show the first 10 rows (i.e. trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take the average across the trials, i.e. the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations_avg = durations.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the average duration of each stimulus step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally to the durations, we would like to know the average time onsets and offsets of the on and off steps relative to the beginning of the trial.\n",
    "\n",
    "![](onoffstepoffsets.png)\n",
    "\n",
    "For this we take the cumulative sum of the average durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_timings = durations_avg.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_timings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now store these on- and offsets into their own variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_start = step_timings[0]\n",
    "on_end = step_timings[1]\n",
    "off_start = step_timings[2]\n",
    "off_end = step_timings[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer to do so, you can also do all of this in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(on_start,\n",
    " on_end,\n",
    " off_start,\n",
    " off_end) = np.diff(stimulus)[:-3].reshape(-1, 4).mean(axis=0).cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the offset of the off-step matches the average length of the trail, here, we round up to the nearest full second. This will come in handy when splitting the trial later into equal-sized bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_end  # The off-step offset is equal to the average trial length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_length = np.ceil(off_end)  # Rounding up to the nearest integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Alignment\n",
    "\n",
    "A typical problem when handling data is the alignment of stimulus and recorded data, since it is not easy to start the stimulus and the recording at exactly the same time. Fortunately, we have the timings of both stimulus and spikes to control for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spike timings from file\n",
    "filepath = Path('data_on_off_steps/8_SP_C3002.txt')\n",
    "spike_times = np.loadtxt(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see here, the first spike occurred before the stimulus started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times[0], stimulus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, the last spike recorded happened after the stimulus had ended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times[-1], stimulus[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line gives us a list of truth values for each spike, as to whether it occurred after stimulus onset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times > stimulus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this list to index `spike_times` to return only the relevant spikes, such that we can simply cut off any spikes occuring before the first stimulus time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times[spike_times > stimulus[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Using this indexing technique retrieve a list of all spikes that occurred within the stimulus times and store it back into `spike_times`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(spikes, stimulus):\n",
    "    \"\"\"\n",
    "    Return those spike times that lie within the stimulus duration\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    spikes : numpy.ndarray\n",
    "        Spike times as one dimensional list, where each element is a\n",
    "        timestamp\n",
    "        \n",
    "    stimulus : numpy.ndarray\n",
    "        Stimulus times as one dimensional list, where each element is\n",
    "        a timestamp\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    spikes : numpy.ndarray\n",
    "        Spike times that are within the stimulus duration\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    spikes = spikes[spikes > stimulus[0]]  # Remove spikes before\n",
    "    spikes = spikes[spikes < stimulus[-1]]  # Remove spikes after\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times = align(spike_times, stimulus)\n",
    "\n",
    "# Let's check if your code is correct\n",
    "print(spike_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**  \n",
    "`[ 10.1834  10.3542  10.3721 ... 413.9438 413.9635 414.1202]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Trials\n",
    "\n",
    "We want to refer to our spike times by the individual stimulus trials. To do so, we want to appoint a trial number to each spike and create separate lists of spikes for each trial.\n",
    "\n",
    "From before we know that every fourth list element (starting with the first) indicates the time onset of each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_onsets(stimulus):\n",
    "    \"\"\"\n",
    "    Return a list of trial onsets given the stimulus times\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    stimulus : numpy.ndarray\n",
    "        Stimulus times as one dimensional list, where each element is\n",
    "        a timestamp\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    trial_onsets : numpy.ndarray\n",
    "        Onsets of each trial\n",
    "    \"\"\"\n",
    "\n",
    "    trial_onsets = stimulus[::4]\n",
    "\n",
    "    return trial_onsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_onsets = get_trial_onsets(stimulus)\n",
    "\n",
    "print(trial_onsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of this list corresponds to the trial onset, while its index corresponds to the trial number. Any spike occurring between the first two elements can be appointed to the first trial, any spike occurring between the second and third element is appointed to the second trial and so on.\n",
    "\n",
    "**Exercise:** Using the function `np.digitize`, that you know from binning spikes, create a list `trial_idx` that contains the trial index that each spike belongs to.  \n",
    "In other words: Each element of `trial_idx` should be the trial number of the spike at the same position in `spike_times`. This will produce a list starting with `[0, 0, 0, 0, 0, ..., 1, 1, 1, 1, ...]`. For indexing with it later start with trial 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_indices(spikes, trial_onsets):\n",
    "    \"\"\"\n",
    "    Return a list of trial indices. Each element is the trial number\n",
    "    corresponding to which each spike belongs to\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    spikes : numpy.ndarray\n",
    "        Spike times as one dimensional list, where each element is a\n",
    "        timestamp\n",
    "        \n",
    "    trial_onsets : numpy.ndarray\n",
    "        Onsets of each trial\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    trial_idx : numpy.ndarray\n",
    "        Trial indices for each spike\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    trial_idx = np.digitize(spike_times, trial_onsets)\n",
    "    trial_idx -= 1  # Start with trial 0\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return trial_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_idx = get_trial_indices(spike_times, trial_onsets)\n",
    "\n",
    "# Let's check if your code is correct\n",
    "print(trial_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**  \n",
    "`[ 0  0  0 ... 67 67 67]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find all spike times that belong to the same trial we use `trial_idx` to index `spike_times`. The code below, for example, returns all spike times that occurred during the first trial (remember indexing starts at 0). As you can see all elements are between `10.045` and `15.998`, which are the first two elements of `trial_onsets` (see above), and define the duration of the first trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times[trial_idx == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each trial, we create a list like the one above and collect all these lists in a list `trials`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trials(spikes, trial_idx, trial_onsets):\n",
    "    \"\"\"\n",
    "    Return the spike times as a list of trials\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    spikes : numpy.ndarray\n",
    "        Spike times as one dimensional list, where each element is a\n",
    "        timestamp\n",
    "    \n",
    "    trial_idx : numpy.ndarray\n",
    "        Trial indices for each spike\n",
    "    \n",
    "    trial_onsets : numpy.ndarray\n",
    "        Onsets of each trial\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    trials : list of numpy.ndarrays\n",
    "        Each list element contains the spike times of one trial\n",
    "    \"\"\"\n",
    "    num_trials = np.unique(trial_idx).size\n",
    "    \n",
    "    trials = []\n",
    "    for trial in range(num_trials):\n",
    "        tr = spike_times[trial_idx == trial]\n",
    "        trials.append(tr)\n",
    "    \n",
    "    return trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remind ourselves: The recording was done continuously and the spike times are steadily increasing. However, we want every trial to start at zero.\n",
    "\n",
    "**Exercise:** Let's replace the function from above and change the content of the loop above to align all trials at zero.  \n",
    "*Hint:* Subtract the trial offset from  the spike_times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trials(spikes, trial_idx, trial_onsets):\n",
    "    \"\"\"\n",
    "    Return the spike times as a list of trials\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    spikes : numpy.ndarray\n",
    "        Spike times as one dimensional list, where each element is a\n",
    "        timestamp\n",
    "    \n",
    "    trial_idx : numpy.ndarray\n",
    "        Trial indices for each spike\n",
    "    \n",
    "    trial_onsets : numpy.ndarray\n",
    "        Onsets of each trial\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    trials : list of numpy.ndarrays\n",
    "        Each list element contains the spike times of one trial\n",
    "    \"\"\"\n",
    "    num_trials = np.unique(trial_idx).size\n",
    "    \n",
    "    trials = []\n",
    "    for trial in range(num_trials):\n",
    "        ### CHANGE CODE HERE ###\n",
    "        tr = spikes[trial_idx == trial] - trial_onsets[trial]\n",
    "        trials.append(tr)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = get_trials(spike_times, trial_idx, trial_onsets)\n",
    "\n",
    "# Let's check if your code is correct\n",
    "print(trials[0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**  \n",
    "`[0.1429 0.3137 0.3316 0.4045 0.6188]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`trials` is now a list of lists with trials by spike times. Let's have a look at the first three trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise**: Now plot the raster for the multiple trials like learned previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "plt.eventplot(trials)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Trial');\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we see a nice structure in the spike times, it is useful to visualize the correpsonding stimulus changes.\n",
    "\n",
    "**Excercise**: Add the following line of code to your raster plot:\n",
    "\n",
    "```python\n",
    "plt.vlines([on_start, on_end, off_start, off_end], 0, num_trials);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "plt.eventplot(trials)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Trial')\n",
    "plt.vlines([on_start, on_end, off_start, off_end], 0, num_trials);\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Plot PSTH\n",
    "\n",
    "A peristimulus time histogram (PSTH) is a histogram indicating how often a neuron spikes. It is useful to investigate the firing rate response of a neuron to a stimulus.\n",
    "\n",
    "First we define bins to collect the spikes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin size\n",
    "dt = 0.01\n",
    "\n",
    "# Divide trial into bins of length dt\n",
    "bins = np.arange(0, trial_length, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we appoint each spike to a bin - similarly as we have done to find the trial indices. To work with `np.digitize` again, we need to flatten `trials` from a list of lists into a one dimensional list. The difference between `trials_flattened` and `spike_times` is that the spike times in `trials_flattened` are counted from each trial onset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appoint bin indices to each spike\n",
    "trials_flattened = np.concatenate(trials)\n",
    "indices = np.digitize(trials_flattened, bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function `np.bincount` we obtain the number of spikes in each bin from which we can obtain the firing rate of the neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count spikes in each bin\n",
    "rate = np.bincount(indices, minlength=len(bins))\n",
    "\n",
    "# Normalize firing rate to spikes per seconds\n",
    "rate = rate / (num_trials*dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All taken together, we obtain this function to retrieve the firing rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_firingrate(trials, trial_length, dt):\n",
    "    \"\"\"\n",
    "    Return the firing rate from the trial list\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trials : list of numpy.ndarrays\n",
    "        Each list element contains the spike times of one trial\n",
    "    \n",
    "    trial_length : int\n",
    "        Length of each trial\n",
    "        \n",
    "    dt : float\n",
    "        Binning size in seconds\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rate : numpy.ndarray\n",
    "        Firing rate averaged over trials (one dimensional list)\n",
    "    \"\"\"\n",
    "    bins = np.arange(0, trial_length, dt)\n",
    "    \n",
    "    trials_flattened = np.concatenate(trials)\n",
    "    indices = np.digitize(trials_flattened, bins)\n",
    "    \n",
    "    rate = np.bincount(indices, minlength=len(bins))\n",
    "    \n",
    "    rate = rate / (num_trials*dt)\n",
    "    \n",
    "    return rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = get_firingrate(trials, trial_length, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the PSTH!\n",
    "\n",
    "Only the first three lines are really necessary. The code below makes the plot more pretty and adds indicators of the stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins, rate, 'k')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Firing rate (Hz)')\n",
    "\n",
    "# Optionally make plot pretty (you may inspect this code if you are interested)\n",
    "\n",
    "# Obtain the axes object from the figure\n",
    "ax = plt.gca()\n",
    "\n",
    "# Create rectangles for the stimulus period in the respective color\n",
    "from matplotlib.patches import Rectangle\n",
    "ax.add_patch(Rectangle((0, -10), width=on_start, height=5, fc='gray'))\n",
    "ax.add_patch(Rectangle((on_start, -10), width=on_end-on_start, height=5,\n",
    "                       fc='lightgray'))\n",
    "ax.add_patch(Rectangle((on_end, -10), width=off_start-on_end, height=5,\n",
    "                       fc='gray'))\n",
    "ax.add_patch(Rectangle((off_start, -10), width=off_end-off_start, height=5,\n",
    "                       fc='black'))\n",
    "\n",
    "# Remove top and right axes, and 'detach' left and bottom axes\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_smart_bounds(True)\n",
    "ax.spines['bottom'].set_smart_bounds(True)\n",
    "\n",
    "# Add some margins to the 'detached' axes\n",
    "ax.margins(x=0.025, y=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Calculate On-Off Index\n",
    "\n",
    "The on-off index allows us to quantify the preference of the cell. The index ranges from `-1` (off cell) to `1` (on cell). It is computed from the on and off periods of the firing rate with\n",
    "\n",
    "$$\n",
    "\\frac{\\sum{r_\\text{on}} - \\sum{r_\\text{off}}}{\\sum{r_\\text{on}} + \\sum{r_\\text{off}}} \\,,\n",
    "$$\n",
    "\n",
    "where $r$ is the firing rate.\n",
    "\n",
    "Let's first define $r_\\text{on}$ (firing rate during on-step) and $r_\\text{off}$ (firing rate during off-step). For those, we'll need to collect the indices of the bins corresponding to the periods (i.e. on-step and off-step). We can find the bins for the different steps by the on and offsets.\n",
    "\n",
    "\\begin{align}\n",
    "\\text{bins}_\\text{on} &= \\text{on}_\\text{onset} \\leq \\text{bins} < \\text{on}_\\text{offset}\\\\\n",
    "\\text{bins}_\\text{off} &= \\text{off}_\\text{onset} \\leq \\text{bins} < \\text{off}_\\text{offset}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_on = []\n",
    "indices_off = []\n",
    "\n",
    "for index, bn in enumerate(bins):\n",
    "    if on_start <= bn < on_end:\n",
    "        indices_on += [index]\n",
    "    elif off_start <= bn < off_end:\n",
    "        indices_off += [index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plug in theses indices into `rate` to obtain $r_\\text{on}$ and $r_\\text{off}$, i.e. `rate_on` and `rate_off`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_on = rate[indices_on]\n",
    "rate_off = rate[indices_off]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Given the indices of the on and off steps, implement the equation above to find the on-off index of the cell and write it to the variable `on_off_idx`.  \n",
    "*Hint:* To sum `rate_on` and `rate_off` use `np.sum()`.  \n",
    "If you are done quickly, try to prevent a possible division-by-zero. The on-off index should be `np.nan` in that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onoffindex(rate, indices_on, indices_off):\n",
    "    \"\"\"\n",
    "    Compute the on-off index from the firing rate and the on- and\n",
    "    off-indices\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rate : numpy.ndarray\n",
    "        Firing rate averaged over trials (one dimensional list)\n",
    "        \n",
    "    indices_on : list\n",
    "        Indices of the firing rate bins of the on step of the stimulus\n",
    "    \n",
    "    indices_off : list\n",
    "        Indices of the firing rate bins of the off step of the stimulus\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    on_off_idx : float\n",
    "        On-off index of the cell\n",
    "    \"\"\"    \n",
    "    rate_on = rate[indices_on]\n",
    "    rate_off = rate[indices_off]\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    rate_on_sum = rate_on.sum()\n",
    "    rate_off_sum = rate_off.sum()\n",
    "\n",
    "    # Calculate on-off index\n",
    "    if rate_on_sum == rate_off_sum == 0:\n",
    "        on_off_idx = np.nan\n",
    "    else:\n",
    "        on_off_idx = (rate_on_sum-rate_off_sum) / (rate_on_sum+rate_off_sum)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return on_off_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_off_idx = get_onoffindex(rate, indices_on, indices_off)\n",
    "\n",
    "# Let's check if your code is correct\n",
    "print(on_off_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**  \n",
    "`-0.8125216188170185`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Compare Multiple Cells\n",
    "\n",
    "Let's compare the on-off index between multiple cells.\n",
    "\n",
    "This means, we'll need to perform all of the analyses above on all cells. Any operations we did regarding the stimulus, however, do not have to be redone, because the stimulus is identical of all cells. But since we have created functions for each step, we'll just have to use these and call them.\n",
    "\n",
    "For each cell we'll have to...\n",
    " 1. Load spike time from file\n",
    " 1. Align the spike times to the stimulus times\n",
    " 1. Split the spike times into trials\n",
    "    - Get the trial onsets\n",
    "    - Get the trial indices\n",
    "    - Get the trials from the indices\n",
    " 1. Compute the firing rates from the trials\n",
    " 1. Compute the on-off index\n",
    " \n",
    "**Note:** We have implemented all of these steps in individual functions, so we don't have to rewrite them, but only call the existing functions.\n",
    " \n",
    "**Exercise:** Scrolling up to the previous pieces of code, call the functions we have written from the loop below.  \n",
    "*Hint:* Since the stimulus is the same for all the cells you can omit retrieval of the onsets and offset as well as the computation of the bin indices for the on-off index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list will collect the on-off indices of all cells\n",
    "on_off_indices = []\n",
    "\n",
    "# Generate a list of the spike files of all cells\n",
    "filenames = [i.name for i in Path('data_on_off_steps').glob('8_SP_C*.txt')]\n",
    "\n",
    "# Iterate over all files\n",
    "for cell in range(len(filenames)):\n",
    "    filepath = Path('data_on_off_steps', filenames[cell])\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # 1. Load spike times from file\n",
    "    spike_times = np.loadtxt(filepath)\n",
    "\n",
    "    # 2. Align the spike times to the stimulus times\n",
    "    spike_times = align(spike_times, stimulus)\n",
    "\n",
    "    # 3. Split the spike times into trials\n",
    "    trial_onsets = get_trial_onsets(stimulus)\n",
    "    trial_idx = get_trial_indices(spike_times, trial_onsets)\n",
    "    trials = get_trials(spike_times, trial_idx, trial_onsets)\n",
    "\n",
    "    # 4. Compute the firing rates from the trials\n",
    "    rate = get_firingrate(trials, trial_length, 0.01)\n",
    "\n",
    "    # 5. Compute the on-off index\n",
    "    on_off_idx = get_onoffindex(rate, indices_on, indices_off)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "\n",
    "    # Append the on-off index to the list\n",
    "    on_off_indices.append(on_off_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check if your code is correct\n",
    "print(on_off_indices[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**  \n",
    "`[0.018091079226450448, 0.009009009009009248, -0.7491289198606271, 0.21944035346097215, -0.8125216188170185]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Visualize the distribution of on-off indices among all cells using a `plt.hist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "plt.hist(on_off_indices, bins=20, range=[-1, 1])\n",
    "plt.xlabel('On-off index')\n",
    "plt.ylabel('Number of cells')\n",
    "plt.legend(['n = ' + str(len(filenames))]);  # Show the number of cells\n",
    "### START CODE HERE ###"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
